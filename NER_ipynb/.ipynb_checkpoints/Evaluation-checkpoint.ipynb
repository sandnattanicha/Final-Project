{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import *\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_df = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/ref_ne_con/eval/piinum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_pii = [i for i in pii_df['real']]\n",
    "stanford_pii = [i for i in pii_df['stanford']]\n",
    "nltk_pii = [i for i in pii_df['nltk']]\n",
    "spacy_pii = [i for i in pii_df['spacy']]\n",
    "com_re_pii = [i for i in pii_df['combined_regex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/ref_ne_con/eval/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford = [i for i in df['stanford']]\n",
    "nltk = [i for i in df['nltk']]\n",
    "spacy = [i for i in df['spacy']]\n",
    "com = [i for i in df['combined']]\n",
    "com_regex = [i for i in df['combined_regex']]\n",
    "real = [i for i in df['real']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE      0.471     0.889     0.615         9\n",
      "    LOCATION      0.400     0.333     0.364         6\n",
      "       MONEY      1.000     1.000     1.000         4\n",
      "           O      0.964     0.987     0.975       817\n",
      "ORGANIZATION      0.286     1.000     0.444         2\n",
      "      PERSON      1.000     0.767     0.868        30\n",
      "      PIINUM      0.000     0.000     0.000        24\n",
      "\n",
      "    accuracy                          0.947       892\n",
      "   macro avg      0.589     0.711     0.610       892\n",
      "weighted avg      0.929     0.947     0.937       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE      0.000     0.000     0.000         9\n",
      "    LOCATION      0.200     0.333     0.250         6\n",
      "       MONEY      0.000     0.000     0.000         4\n",
      "           O      0.934     0.946     0.940       817\n",
      "ORGANIZATION      0.000     0.000     0.000         2\n",
      "      PERSON      0.333     0.600     0.429        30\n",
      "      PIINUM      0.000     0.000     0.000        24\n",
      "\n",
      "    accuracy                          0.889       892\n",
      "   macro avg      0.210     0.268     0.231       892\n",
      "weighted avg      0.868     0.889     0.877       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE      0.529     1.000     0.692         9\n",
      "    LOCATION      0.000     0.000     0.000         6\n",
      "       MONEY      1.000     1.000     1.000         4\n",
      "           O      0.973     0.988     0.981       817\n",
      "ORGANIZATION      0.333     1.000     0.500         2\n",
      "      PERSON      0.938     1.000     0.968        30\n",
      "      PIINUM      0.000     0.000     0.000        24\n",
      "     PRODUCT      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.955       892\n",
      "   macro avg      0.472     0.623     0.518       892\n",
      "weighted avg      0.934     0.955     0.943       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE      0.529     1.000     0.692         9\n",
      "    LOCATION      1.000     0.167     0.286         6\n",
      "       MONEY      1.000     1.000     1.000         4\n",
      "           O      0.969     0.988     0.978       817\n",
      "ORGANIZATION      0.400     1.000     0.571         2\n",
      "      PERSON      0.938     1.000     0.968        30\n",
      "      PIINUM      0.000     0.000     0.000        24\n",
      "\n",
      "    accuracy                          0.956       892\n",
      "   macro avg      0.691     0.736     0.642       892\n",
      "weighted avg      0.936     0.956     0.943       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE      0.529     1.000     0.692         9\n",
      "    LOCATION      1.000     0.167     0.286         6\n",
      "       MONEY      1.000     1.000     1.000         4\n",
      "           O      0.995     0.988     0.991       817\n",
      "ORGANIZATION      0.400     1.000     0.571         2\n",
      "      PERSON      0.938     1.000     0.968        30\n",
      "      PIINUM      1.000     0.917     0.957        24\n",
      "\n",
      "    accuracy                          0.981       892\n",
      "   macro avg      0.837     0.867     0.781       892\n",
      "weighted avg      0.987     0.981     0.981       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(real, stanford, digits = 3))\n",
    "print(metrics.classification_report(real, nltk, digits = 3))\n",
    "print(metrics.classification_report(real, spacy, digits = 3))\n",
    "print(metrics.classification_report(real, com, digits = 3))\n",
    "print(metrics.classification_report(real, com_regex, digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.973     1.000     0.986       868\n",
      "      PIINUM      0.000     0.000     0.000        24\n",
      "\n",
      "    accuracy                          0.973       892\n",
      "   macro avg      0.487     0.500     0.493       892\n",
      "weighted avg      0.947     0.973     0.960       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(ref_pii, stanford_pii, digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.973     1.000     0.986       868\n",
      "      PIINUM      0.000     0.000     0.000        24\n",
      "\n",
      "    accuracy                          0.973       892\n",
      "   macro avg      0.487     0.500     0.493       892\n",
      "weighted avg      0.947     0.973     0.960       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(ref_pii, nltk_pii, digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.97      1.00      0.99       868\n",
      "      PIINUM       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.97       892\n",
      "   macro avg       0.49      0.50      0.49       892\n",
      "weighted avg       0.95      0.97      0.96       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(ref_pii, spacy_pii, digits = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.998     1.000     0.999       868\n",
      "      PIINUM      1.000     0.917     0.957        24\n",
      "\n",
      "    accuracy                          0.998       892\n",
      "   macro avg      0.999     0.958     0.978       892\n",
      "weighted avg      0.998     0.998     0.998       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(ref_pii, com_re_pii, digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/ref_ne_con/eval/all2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford2 = [i for i in oa['stanford']]\n",
    "nltk2 = [i for i in oa['nltk']]\n",
    "spacy2 = [i for i in oa['spacy']]\n",
    "com2 = [i for i in oa['combined']]\n",
    "com_regex2 = [i for i in oa['combined_regex']]\n",
    "real2 = [i for i in oa['real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.780     0.520     0.624        75\n",
      "           O      0.957     0.987     0.972       817\n",
      "\n",
      "    accuracy                          0.947       892\n",
      "   macro avg      0.869     0.753     0.798       892\n",
      "weighted avg      0.942     0.947     0.942       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.312     0.267     0.288        75\n",
      "           O      0.934     0.946     0.940       817\n",
      "\n",
      "    accuracy                          0.889       892\n",
      "   macro avg      0.623     0.606     0.614       892\n",
      "weighted avg      0.881     0.889     0.885       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.818     0.600     0.692        75\n",
      "           O      0.964     0.988     0.976       817\n",
      "\n",
      "    accuracy                          0.955       892\n",
      "   macro avg      0.891     0.794     0.834       892\n",
      "weighted avg      0.952     0.955     0.952       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.957     0.587     0.727        75\n",
      "           O      0.963     0.998     0.980       817\n",
      "\n",
      "    accuracy                          0.963       892\n",
      "   macro avg      0.960     0.792     0.854       892\n",
      "weighted avg      0.963     0.963     0.959       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.971     0.880     0.923        75\n",
      "           O      0.989     0.998     0.993       817\n",
      "\n",
      "    accuracy                          0.988       892\n",
      "   macro avg      0.980     0.939     0.958       892\n",
      "weighted avg      0.988     0.988     0.987       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(real2, stanford2, digits = 3))\n",
    "print(metrics.classification_report(real2, nltk2, digits = 3))\n",
    "print(metrics.classification_report(real2, spacy2, digits = 3))\n",
    "print(metrics.classification_report(real2, com2, digits = 3))\n",
    "print(metrics.classification_report(real2, com_regex2, digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/ref_ne_con/eval/person.csv')\n",
    "stanford = [i for i in df['stanford']]\n",
    "nltk = [i for i in df['nltk']]\n",
    "spacy = [i for i in df['spacy']]\n",
    "com_regex = [i for i in df['combined_regex']]\n",
    "real = [i for i in df['real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9955156950672646\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(real, stanford))\n",
    "print(accuracy(real, nltk))\n",
    "print(accuracy(real, spacy))\n",
    "print(accuracy(real, com_regex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.992     1.000     0.996       862\n",
      "      PERSON      1.000     0.767     0.868        30\n",
      "\n",
      "    accuracy                          0.992       892\n",
      "   macro avg      0.996     0.883     0.932       892\n",
      "weighted avg      0.992     0.992     0.992       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.986     1.000     0.993       862\n",
      "      PERSON      1.000     0.600     0.750        30\n",
      "\n",
      "    accuracy                          0.987       892\n",
      "   macro avg      0.993     0.800     0.872       892\n",
      "weighted avg      0.987     0.987     0.985       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      1.000     1.000     1.000       862\n",
      "      PERSON      1.000     1.000     1.000        30\n",
      "\n",
      "    accuracy                          1.000       892\n",
      "   macro avg      1.000     1.000     1.000       892\n",
      "weighted avg      1.000     1.000     1.000       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.998     1.000     0.999       862\n",
      "      PERSON      1.000     0.933     0.966        30\n",
      "\n",
      "    accuracy                          0.998       892\n",
      "   macro avg      0.999     0.967     0.982       892\n",
      "weighted avg      0.998     0.998     0.998       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(real, stanford, digits = 3))\n",
    "print(metrics.classification_report(real, nltk, digits = 3))\n",
    "print(metrics.classification_report(real, spacy, digits = 3))\n",
    "print(metrics.classification_report(real, com_regex, digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
