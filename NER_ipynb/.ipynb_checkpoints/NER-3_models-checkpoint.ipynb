{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Using 3 Models and Rules-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK and Stanford libraries\n",
    "import nltk, re, os\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tree import Tree\n",
    "from nltk import RegexpParser\n",
    "from nltk.chunk.api import ChunkParserI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy libraries\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transcript': \"Hello, you have called virtual bank. This is Sarah speaking. How may I help you? Hey sir, I would to refund my money back. Could you tell me why you want to refund your money? I bought something at the shop with my debit card on the 2nd of December 2019 and it debited my money twice. Okay. What is your name Madam? My name is Amy golf golf. Okay, I have Amy Gough Gough and where did you use the debit card to buy something? I bought a bag at Mega bangna it costs $800 were so sorry. In this case. We could not refund your money back. You have to talk with the store that you bought and they will manage. Judge this oh, really? I do not even know. Yes madam. We're so sorry, but we could not fix this problem the store handles about this. Okay, nevermind. Thanks. Would you like another service? That is all thanks. Thank you for using our service. Have a good day.\", 'values': {'start': [0.0, 0.5, 0.6, 0.8, 1.1, 1.6, 2.0, 2.1, 2.3, 2.7, 3.2, 3.4, 3.6, 3.7, 4.0, 4.2, 4.4, 4.7, 4.9, 5.1, 5.2, 5.6, 5.8, 6.1, 6.4, 6.6, 6.7, 6.9, 7.1, 7.3, 7.4, 7.7, 7.8, 8.2, 8.3, 8.7, 8.7, 9.0, 9.5, 9.6, 9.7, 10.0, 10.2, 10.3, 10.7, 11.1, 11.2, 11.3, 11.6, 11.7, 12.2, 13.2, 13.3, 13.4, 13.8, 13.9, 14.2, 14.6, 14.9, 15.1, 15.2, 15.3, 15.6, 15.9, 16.0, 16.3, 16.5, 16.7, 17.1, 17.4, 17.7, 17.8, 18.0, 18.3, 18.6, 19.0, 19.1, 19.3, 19.4, 19.6, 19.8, 19.9, 20.2, 20.6, 20.7, 20.9, 21.4, 21.5, 21.7, 21.7, 22.1, 22.2, 22.5, 22.9, 23.0, 23.4, 24.3, 24.4, 24.7, 25.1, 25.2, 25.4, 25.8, 25.9, 26.0, 26.3, 26.6, 26.8, 27.0, 27.4, 27.5, 27.7, 27.8, 28.1, 28.2, 28.3, 28.7, 28.8, 29.0, 29.3, 29.4, 29.5, 29.6, 30.0, 30.1, 30.4, 30.6, 30.9, 31.0, 31.1, 31.4, 31.6, 31.8, 32.1, 32.4, 32.6, 32.8, 33.3, 33.4, 33.5, 33.7, 33.9, 34.2, 34.4, 34.9, 35.0, 35.4, 35.8, 36.1, 36.3, 36.6, 37.2, 37.6, 37.8, 37.9, 38.1, 38.4, 38.9, 39.0, 39.2, 39.3, 39.7, 40.0, 40.2, 40.3, 40.7, 40.8, 41.4, 41.5, 41.6, 41.8], 'end': [0.5, 0.6, 0.8, 1.1, 1.6, 2.0, 2.1, 2.3, 2.7, 3.2, 3.4, 3.6, 3.7, 4.0, 4.2, 4.4, 4.7, 4.9, 5.1, 5.2, 5.6, 5.8, 6.1, 6.4, 6.6, 6.7, 6.9, 7.1, 7.3, 7.4, 7.7, 7.8, 8.2, 8.3, 8.7, 8.7, 9.0, 9.5, 9.6, 9.7, 10.0, 10.2, 10.3, 10.7, 11.1, 11.2, 11.3, 11.6, 11.7, 12.2, 13.2, 13.3, 13.4, 13.8, 13.9, 14.2, 14.6, 14.9, 15.1, 15.2, 15.3, 15.6, 15.9, 16.0, 16.3, 16.5, 16.7, 17.1, 17.4, 17.7, 17.8, 18.0, 18.3, 18.6, 19.0, 19.1, 19.3, 19.4, 19.6, 19.8, 19.9, 20.2, 20.6, 20.7, 20.9, 21.4, 21.5, 21.7, 21.7, 22.1, 22.2, 22.5, 22.9, 23.0, 23.4, 24.3, 24.4, 24.7, 25.1, 25.2, 25.4, 25.8, 25.9, 26.0, 26.3, 26.6, 26.8, 27.0, 27.4, 27.5, 27.7, 27.8, 28.1, 28.2, 28.3, 28.7, 28.8, 29.0, 29.3, 29.4, 29.5, 29.6, 29.9, 30.1, 30.4, 30.6, 30.9, 31.0, 31.1, 31.4, 31.6, 31.8, 32.1, 32.4, 32.6, 32.8, 33.3, 33.4, 33.5, 33.7, 33.9, 34.2, 34.4, 34.9, 35.0, 35.4, 35.8, 36.1, 36.3, 36.6, 37.2, 37.6, 37.8, 37.9, 38.1, 38.4, 38.9, 39.0, 39.2, 39.3, 39.7, 40.0, 40.2, 40.3, 40.7, 40.8, 41.4, 41.5, 41.6, 41.8, 42.3], 'word': ['Hello,', 'you', 'have', 'called', 'virtual', 'bank.', 'This', 'is', 'Sarah', 'speaking.', 'How', 'may', 'I', 'help', 'you?', 'Hey', 'sir,', 'I', 'would', 'to', 'refund', 'my', 'money', 'back.', 'Could', 'you', 'tell', 'me', 'why', 'you', 'want', 'to', 'refund', 'your', 'money?', 'I', 'bought', 'something', 'at', 'the', 'shop', 'with', 'my', 'debit', 'card', 'on', 'the', '2nd', 'of', 'December', '2019', 'and', 'it', 'debited', 'my', 'money', 'twice.', 'Okay.', 'What', 'is', 'your', 'name', 'Madam?', 'My', 'name', 'is', 'Amy', 'golf', 'golf.', 'Okay,', 'I', 'have', 'Amy', 'Gough', 'Gough', 'and', 'where', 'did', 'you', 'use', 'the', 'debit', 'card', 'to', 'buy', 'something?', 'I', 'bought', 'a', 'bag', 'at', 'Mega', 'bangna', 'it', 'costs', '$800', 'were', 'so', 'sorry.', 'In', 'this', 'case.', 'We', 'could', 'not', 'refund', 'your', 'money', 'back.', 'You', 'have', 'to', 'talk', 'with', 'the', 'store', 'that', 'you', 'bought', 'and', 'they', 'will', 'manage.', 'Judge', 'this', 'oh,', 'really?', 'I', 'do', 'not', 'even', 'know.', 'Yes', 'madam.', \"We're\", 'so', 'sorry,', 'but', 'we', 'could', 'not', 'fix', 'this', 'problem', 'the', 'store', 'handles', 'about', 'this.', 'Okay,', 'nevermind.', 'Thanks.', 'Would', 'you', 'like', 'another', 'service?', 'That', 'is', 'all', 'thanks.', 'Thank', 'you', 'for', 'using', 'our', 'service.', 'Have', 'a', 'good', 'day.']}}\n"
     ]
    }
   ],
   "source": [
    "# reading json file\n",
    "with open('D:/DSBA/Project/Final-Project-2/dict.json', 'r') as json_file:\n",
    "    f = json.load(json_file)\n",
    "data = f\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hello,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>you</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>have</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>called</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>virtual</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>bank.</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>This</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>is</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>speaking.</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       word  start_time  end_time\n",
       "0      0     Hello,         0.0       0.5\n",
       "1      1        you         0.5       0.6\n",
       "2      2       have         0.6       0.8\n",
       "3      3     called         0.8       1.1\n",
       "4      4    virtual         1.1       1.6\n",
       "5      5      bank.         1.6       2.0\n",
       "6      6       This         2.0       2.1\n",
       "7      7         is         2.1       2.3\n",
       "8      8      Sarah         2.3       2.7\n",
       "9      9  speaking.         2.7       3.2"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'count': ([X for X in range(len(data['values']['word']))]), 'word': data['values']['word'], 'start_time': data['values']['start'], 'end_time': data['values']['end']})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford NER Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 3 models\n",
    "\n",
    "* 3 classes model for recognizing locations, person, and organizations\n",
    "* 4 classes model for recognizing locations, person, organizations, and miscellaneous entities\n",
    "* 7 classes model for recognizing locations, person, organizations, times, money, percents, and dates\n",
    "\n",
    "In this project, we use 7 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanford_tagger(document):\n",
    "    lst_word = []\n",
    "    lst_ne = []\n",
    "    lst_count = []\n",
    "    # lst_ps = []\n",
    "    java_path = (\"C:/Program Files/Java/jdk-15.0.1/bin/java.exe\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "    jar = ('D:/Program/stanford-ner-4.0.0/stanford-ner.jar')\n",
    "    model = ('D:/Program/stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser') # 7 classes\n",
    "    st = StanfordNERTagger(model, jar, encoding = 'utf-8')\n",
    "    \n",
    "    # word_token = word_tokenize(document)\n",
    "    classified_text = st.tag(document['word'])\n",
    "    \n",
    "    # token_df = pd.DataFrame({'count': ([X for X in range(len(word_token))]),'word': ([X for X in word_token])})\n",
    "    \n",
    "    for i in range(len(classified_text)):\n",
    "        if str(classified_text[i][1]) != 'O':\n",
    "            lst_word.append(str(classified_text[i][0]))\n",
    "            lst_ne.append(str(classified_text[i][1]))\n",
    "            lst_count.append(i)\n",
    "    st_df = pd.DataFrame({'count': lst_count,'word': lst_word, 'stanford_ne': lst_ne})\n",
    "    # ps_df = st_df[st_df['ne'] == 'PERSON']\n",
    "    \n",
    "    # for w in st_df['word']:\n",
    "        # lst_ps.append(w)\n",
    "            # print(str(classified_text[i][0]), '>>',  str(classified_text[i][1]))\n",
    "    return st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>stanford_ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>speaking.</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>December</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2019</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       word stanford_ne\n",
       "0      8      Sarah      PERSON\n",
       "1      9  speaking.      PERSON\n",
       "2     49   December        DATE\n",
       "3     50       2019        DATE\n",
       "4     72        Amy      PERSON\n",
       "5     73      Gough      PERSON\n",
       "6     74      Gough      PERSON"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_df = stanford_tagger(df)\n",
    "st_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLTK recognizes the following entities:**\n",
    "* ORGANIZATION - Georgia-Pacific Corp., WHO\n",
    "* PERSON - Eddy Bonte, President Obama\n",
    "* LOCATION - Murray River, Mount Everest\n",
    "* DATE - June, 2008-06-29\n",
    "* TIME - two fifty a m, 1:30 p.m.\n",
    "* MONEY - 175 million Canadian Dollars, GBP 10.40\n",
    "* PERCENT - twenty pct, 18.75 %\n",
    "* FACILITY - Washington Monument, Stonehenge\n",
    "* GPE - South East Asia, Midlothian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(df['word'])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_word = []\n",
    "lst_ne = []\n",
    "lst_count = []\n",
    "\n",
    "tagged_words = pos_tag(df['word'])\n",
    "ne_tagged = ne_chunk(tagged_words, binary = False)\n",
    "\n",
    "for chunk in range(len(ne_tagged)):\n",
    "    if hasattr(ne_tagged[chunk], 'label'):\n",
    "        lst_word.append(str(ne_tagged[chunk][0][0]))\n",
    "        lst_ne.append(str(ne_tagged[chunk].label()))\n",
    "        lst_count.append(chunk)\n",
    "    if not hasattr(ne_tagged[chunk], 'label'):\n",
    "        if str(ne_tagged[chunk][0:][1:][0]) == 'CD':\n",
    "            lst_word.append(str(ne_tagged[chunk][0]))\n",
    "            lst_ne.append(str(ne_tagged[chunk][0:][1:][0]))\n",
    "            lst_count.append(chunk)\n",
    "            \n",
    "nltk_df = pd.DataFrame({'count': lst_count, 'word': lst_word, 'nltk_ne': lst_ne})\n",
    "nltk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tagger(document):\n",
    "    lst_word = []\n",
    "    lst_ne = []\n",
    "    lst_count = []\n",
    "    \n",
    "    # word_token = word_tokenize(document)\n",
    "    tagged_words = pos_tag(document['word'])\n",
    "    ne_tagged = ne_chunk(tagged_words, binary = False) # False for details NE type\n",
    "    # ne_tagged.draw()\n",
    "    \n",
    "    for chunk in range(len(ne_tagged)):\n",
    "        if hasattr(ne_tagged[chunk], 'label'):\n",
    "            lst_word.append(str(ne_tagged[chunk][0][0]))\n",
    "            lst_ne.append(str(ne_tagged[chunk].label()))\n",
    "            lst_count.append(chunk)\n",
    "        if not hasattr(ne_tagged[chunk], 'label'):\n",
    "            if str(ne_tagged[chunk][0:][1:][0]) == 'CD':\n",
    "                lst_word.append(str(ne_tagged[chunk][0]))\n",
    "                lst_ne.append(str(ne_tagged[chunk][0:][1:][0]))\n",
    "                lst_count.append(chunk)\n",
    "            \n",
    "    nltk_df = pd.DataFrame({'count': lst_count, 'word': lst_word, 'nltk_ne': lst_ne})\n",
    "    \n",
    "    return nltk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>nltk_ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>Hey</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>2nd</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2019</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89</td>\n",
       "      <td>Mega</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count   word       nltk_ne\n",
       "0      8  Sarah        PERSON\n",
       "1     15    Hey        PERSON\n",
       "2     47    2nd            CD\n",
       "3     50   2019            CD\n",
       "4     66    Amy        PERSON\n",
       "5     72    Amy        PERSON\n",
       "6     89   Mega  ORGANIZATION\n",
       "7    130    Yes        PERSON"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_df = nltk_tagger(df)\n",
    "nltk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spaCy recognizes the following entities:**\n",
    "* PERSON - People, including fictional.\n",
    "* NORP - Nationalities or religious or political groups.\n",
    "* FAC - Buildings, airports, highways, bridges, etc.\n",
    "* ORG - Companies, agencies, institutions, etc.\n",
    "* GPE - Countries, cities, states.\n",
    "* LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "* PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "* EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "* WORK_OF_ART - Titles of books, songs, etc.\n",
    "* LAW - Named documents made into laws.\n",
    "* LANGUAGE - Any named language.\n",
    "* DATE - Absolute or relative dates or periods.\n",
    "* TIME - Times smaller than a day.\n",
    "* PERCENT - Percentage, including ”%“.\n",
    "* MONEY - Monetary values, including unit.\n",
    "* QUANTITY - Measurements, as of weight or distance.\n",
    "* ORDINAL - “first”, “second”, etc.\n",
    "* CARDINAL - Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IOB Scheme**\n",
    "* \"I\" : Token is inside an entity.\n",
    "* \"O\" : Token is outside an entity.\n",
    "* \"B\" : Token begins an entity.\n",
    "* \"\"  : No entity tag is set (missing value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('called', '', 'O'),\n",
      " ('virtual', '', 'O'),\n",
      " ('bank', '', 'O'),\n",
      " ('this', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('linda', 'PERSON', 'B'),\n",
      " ('speaking', '', 'O'),\n",
      " ('how', '', 'O'),\n",
      " ('may', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('help', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('hi', '', 'O'),\n",
      " ('linda', 'PERSON', 'B'),\n",
      " ('i', '', 'O'),\n",
      " ('was', '', 'O'),\n",
      " ('just', '', 'O'),\n",
      " ('at', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('ville', 'GPE', 'B'),\n",
      " ('branch', '', 'O'),\n",
      " ('and', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('think', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('left', '', 'O'),\n",
      " ('my', '', 'O'),\n",
      " ('debit', '', 'O'),\n",
      " ('card', '', 'O'),\n",
      " ('in', '', 'O'),\n",
      " ('the', '', 'O'),\n",
      " ('atm', 'ORG', 'B'),\n",
      " ('machine', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('do', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('debit', '', 'O'),\n",
      " ('card', '', 'O'),\n",
      " ('number', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('do', '', 'O'),\n",
      " ('n’t', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('well', '', 'O'),\n",
      " ('do', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('the', '', 'O'),\n",
      " ('checking', '', 'O'),\n",
      " ('account', '', 'O'),\n",
      " ('number', '', 'O'),\n",
      " ('associated', '', 'O'),\n",
      " ('with', '', 'O'),\n",
      " ('the', '', 'O'),\n",
      " ('debit', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('card', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('that', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('do', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('are', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('ready', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('will', '', 'O'),\n",
      " ('give', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('what', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('got', '', 'O'),\n",
      " ('765456789', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('that', '', 'O'),\n",
      " ('’s', '', 'O'),\n",
      " ('765456789', 'DATE', 'B'),\n",
      " ('\\n', '', 'O'),\n",
      " ('correct', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('what', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('identification', '', 'O'),\n",
      " ('number', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('7745896589665', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('7745896589665', 'DATE', 'B'),\n",
      " ('and', '', 'O'),\n",
      " ('what', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('name', '', 'O'),\n",
      " ('sir', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('it', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('robert', 'PERSON', 'B'),\n",
      " ('applebaum', 'PERSON', 'I'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('robert', 'PERSON', 'B'),\n",
      " ('applebaum', 'PERSON', 'I'),\n",
      " ('\\n', 'PERSON', 'I'),\n",
      " ('yes', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('and', '', 'O'),\n",
      " ('what', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('date', '', 'O'),\n",
      " ('of', '', 'O'),\n",
      " ('birth', '', 'O'),\n",
      " ('mr', '', 'O'),\n",
      " ('applebaum', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('july', 'DATE', 'B'),\n",
      " ('7th', 'DATE', 'I'),\n",
      " ('1974', 'DATE', 'I'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('july', 'DATE', 'B'),\n",
      " ('7th', 'DATE', 'I'),\n",
      " ('1974', 'DATE', 'I'),\n",
      " ('\\n', '', 'O'),\n",
      " ('yes', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('and', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('phone', '', 'O'),\n",
      " ('number', '', 'O'),\n",
      " ('?', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('it', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('6102651715', 'DATE', 'B'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('6102651715', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('yes', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('okay', '', 'O'),\n",
      " ('mr', '', 'O'),\n",
      " ('applebaum', '', 'O'),\n",
      " ('i', '', 'O'),\n",
      " ('have', '', 'O'),\n",
      " ('just', '', 'O'),\n",
      " ('suspended', '', 'O'),\n",
      " ('your', '', 'O'),\n",
      " ('card', '', 'O'),\n",
      " ('if', '', 'O'),\n",
      " ('it', '', 'O'),\n",
      " ('is', '', 'O'),\n",
      " ('in', '', 'O'),\n",
      " ('the', '', 'O'),\n",
      " ('machine', '', 'O'),\n",
      " ('we', '', 'O'),\n",
      " ('will', '', 'O'),\n",
      " ('contact', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('and', '', 'O'),\n",
      " ('lift', '', 'O'),\n",
      " ('the', '', 'O'),\n",
      " ('suspension', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('oh', '', 'O'),\n",
      " ('thank', '', 'O'),\n",
      " ('you', '', 'O'),\n",
      " ('\\n', '', 'O'),\n",
      " ('sure', '', 'O'),\n",
      " ('thank', '', 'O'),\n",
      " ('you', '', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# IOB Scheme\n",
    "pprint([(X.text, X.ent_type_, X.ent_iob_) for X in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # replace . and a space with only a space\n",
    "    text = text.replace(\".\", \"\").replace(\",\", \"\").replace(\"?\", \"\").replace(\"$\", \"\").replace(\"\\'\", \"\")\n",
    "    # get rid of the . at the end of each line. \n",
    "    cleaned_text = re.sub(\"\\.$\", \"\", text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def spaCy_tagger(document):\n",
    "    new_words = []\n",
    "    new_tokens = []\n",
    "    count = []\n",
    "    \n",
    "    nlp = en_core_web_sm.load()\n",
    "    doc = nlp(clean_text(document))\n",
    "    \n",
    "    for token in range(len(doc)):\n",
    "        if doc[token].ent_type_ != '':\n",
    "            if doc[token].ent_type_ == 'DATE':\n",
    "                if (doc[token].text != 'a') and (doc[token].text != 'good') and (doc[token].text != 'day'):\n",
    "                    new_words.append(doc[token].text)\n",
    "                    new_tokens.append(doc[token].ent_type_)\n",
    "                    count.append(token)\n",
    "            elif doc[token].ent_type_ == 'GPE' or doc[token].ent_type_ == 'LOC':\n",
    "                new_words.append(doc[token].text)\n",
    "                new_tokens.append('LOCATION')\n",
    "                count.append(token)\n",
    "            elif doc[token].ent_type_ == 'ORG':\n",
    "                new_words.append(doc[token].text)\n",
    "                new_tokens.append('ORGANIZATION')\n",
    "                count.append(token)\n",
    "            else:\n",
    "                new_words.append(doc[token].text)\n",
    "                new_tokens.append(doc[token].ent_type_)\n",
    "                count.append(token)\n",
    "     \n",
    "    spc_df = pd.DataFrame({'count': count, 'word': new_words, 'spacy_ne': new_tokens})\n",
    "    \n",
    "    return spc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>spacy_ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>the</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>2nd</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>of</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>December</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>2019</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      word spacy_ne\n",
       "0      8     Sarah   PERSON\n",
       "1     46       the     DATE\n",
       "2     47       2nd     DATE\n",
       "3     48        of     DATE\n",
       "4     49  December     DATE\n",
       "5     50      2019     DATE\n",
       "6     66       Amy   PERSON\n",
       "7     72       Amy   PERSON\n",
       "8     73     Gough   PERSON\n",
       "9     74     Gough   PERSON"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spc_df = spaCy_tagger(data['transcript'])\n",
    "spc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/spacy-ner-tagger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Hello, you have called Virtual bank, this is Linda speaking. How may I help you?\n",
    "Hi Linda. I was just at your Ville branch and I think I left my Debit card in the ATM machine.\n",
    "Okay. Do you have your Debit card number?\n",
    "I don’t have.\n",
    "Okay, well do you have the checking account number associated with the Debit\n",
    "card? \n",
    "That I do have. Are you ready? I will give you what I have got. 765456789. \n",
    "Okay. That’s 765456789.\n",
    "Correct.\n",
    "What is your identification number?\n",
    "7745896589665.\n",
    "Okay, I have 7745896589665 and what is your name sir? \n",
    "It is Robert Applebaum.\n",
    "Okay. I have Robert Applebaum.\n",
    "Yes.\n",
    "And what is your date of birth Mr. Applebaum?\n",
    "July 7th, 1974. \n",
    "Okay. July 7th, 1974.\n",
    "Yes.\n",
    "And your phone number?\n",
    "It is 6102651715. \n",
    "Okay. I have 6102651715.\n",
    "Yes.\n",
    "Okay Mr. Applebaum. I have just suspended your card. If it is in the machine, we will contact you and lift the suspension. \n",
    "Oh, thank you.\n",
    "Sure. Thank you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, you have called Virtual bank, this is Linda speaking.',\n",
       " 'How may I help you?',\n",
       " 'Hi Linda.',\n",
       " 'I was just at your Ville branch and I think I left my Debit card in the ATM machine.',\n",
       " 'Okay.',\n",
       " 'Do you have your Debit card number?',\n",
       " 'I don’t have.',\n",
       " 'Okay, well do you have the checking account number associated with the Debit\\ncard?',\n",
       " 'That I do have.',\n",
       " 'Are you ready?',\n",
       " 'I will give you what I have got.',\n",
       " '765456789.',\n",
       " 'Okay.',\n",
       " 'That’s 765456789.',\n",
       " 'Correct.',\n",
       " 'What is your identification number?',\n",
       " '7745896589665.',\n",
       " 'Okay, I have 7745896589665 and what is your name sir?',\n",
       " 'It is Robert Applebaum.',\n",
       " 'Okay.',\n",
       " 'I have Robert Applebaum.',\n",
       " 'Yes.',\n",
       " 'And what is your date of birth Mr. Applebaum?',\n",
       " 'July 7th, 1974.',\n",
       " 'Okay.',\n",
       " 'July 7th, 1974.',\n",
       " 'Yes.',\n",
       " 'And your phone number?',\n",
       " 'It is 6102651715.',\n",
       " 'Okay.',\n",
       " 'I have 6102651715.',\n",
       " 'Yes.',\n",
       " 'Okay Mr. Applebaum.',\n",
       " 'I have just suspended your card.',\n",
       " 'If it is in the machine, we will contact you and lift the suspension.',\n",
       " 'Oh, thank you.',\n",
       " 'Sure.',\n",
       " 'Thank you.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent = sent_tokenize(sentence)\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't use my old phone number anymore, but ...</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's one one one five four four two two two?</td>\n",
       "      <td>ACCNUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My identification number is 1 1 0 2 5 6 9 8 5 ...</td>\n",
       "      <td>IDCARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Five four two 9800 11-2.</td>\n",
       "      <td>IDCARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My phone number is seven.</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seven one nine eight five five five eight seven.</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent        ne\n",
       "0  I didn't use my old phone number anymore, but ...  PHONENUM\n",
       "1     That's one one one five four four two two two?    ACCNUM\n",
       "2  My identification number is 1 1 0 2 5 6 9 8 5 ...    IDCARD\n",
       "3                           Five four two 9800 11-2.    IDCARD\n",
       "4                          My phone number is seven.  PHONENUM\n",
       "5   Seven one nine eight five five five eight seven.  PHONENUM"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlst = []\n",
    "nelst = []\n",
    "\n",
    "for i in range(0, len(tokenized_sent)):\n",
    "    if re.search('phone number', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('PHONENUM')\n",
    "        elif re.search('([0-9]|zero|one|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2])  or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('PHONENUM')\n",
    "    if re.search('account number', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('ACCNUM')\n",
    "        elif re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('ACCNUM')\n",
    "    if re.search('(identify number|identification number)', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('IDCARD')\n",
    "        elif re.search('([0-9]|zero|one|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('IDCARD')\n",
    "\n",
    "pd.DataFrame({'sent': wlst, 'ne': nelst})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
