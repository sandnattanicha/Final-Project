{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Using 3 Models and Rules-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others libraries\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK and Stanford libraries\n",
    "import nltk, re, os\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tree import Tree\n",
    "from nltk import RegexpParser\n",
    "from nltk.chunk.api import ChunkParserI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy libraries\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading json file and storing in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load(path):\n",
    "    # reading json file\n",
    "    with open(path, 'r') as json_file:\n",
    "        f = json.load(json_file)\n",
    "    data = f\n",
    "    \n",
    "    # Collecting index of word, word, start time, and end time\n",
    "    df = pd.DataFrame({'indx': ([X for X in range(len(data['values']['word']))]),\n",
    "                       'word': data['values']['word'], 'start_time': data['values']['start'],\n",
    "                       'end_time': data['values']['end']})\n",
    "    \n",
    "    df = df.set_index('indx')\n",
    "    \n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, df = read_load('D:/DSBA/Project/Final-Project-2/Nancy-Sandra.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford NER Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "It has 3 models\n",
    "\n",
    "* 3 classes model for recognizing locations, person, and organizations\n",
    "* 4 classes model for recognizing locations, person, organizations, and miscellaneous entities\n",
    "* 7 classes model for recognizing locations, person, organizations, times, money, percents, and dates\n",
    "\n",
    "In this project, we use 7 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stanford_pred(dictt, df):\n",
    "    \n",
    "    java_path = (\"C:/Program Files/Java/jdk-15.0.1/bin/java.exe\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "    jar = ('D:/Program/stanford-ner-4.0.0/stanford-ner.jar')\n",
    "    model = ('D:/Program/stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser') # 7 classes\n",
    "    st = StanfordNERTagger(model, jar, encoding = 'utf-8')\n",
    "    \n",
    "    word_token = word_tokenize(dictt)\n",
    "    classified_text = st.tag(word_token)\n",
    "\n",
    "    wordlst = []\n",
    "    ne_lst = []\n",
    "\n",
    "    for i in range(len(classified_text)):\n",
    "        if str(classified_text[i][1]) != 'O':\n",
    "            if str(classified_text[i][1]) == 'PERSON' or str(classified_text[i][1]) == 'LOCATION' or str(classified_text[i][1]) == 'ORGANIZATION' or str(classified_text[i][1]) == 'MONEY' or str(classified_text[i][1]) == 'DATE':\n",
    "                wordlst.append(str(classified_text[i][0]))\n",
    "                ne_lst.append(str(classified_text[i][1]))\n",
    "                \n",
    "    st_pred = []        \n",
    "    check = 0  \n",
    "\n",
    "    for ww in df['word']:\n",
    "        check = 0\n",
    "        for w, n in zip(wordlst, ne_lst):\n",
    "            if ww.__contains__(w):\n",
    "                check = 1\n",
    "                st_pred.append(str(n))\n",
    "                break\n",
    "        if check == 0:\n",
    "            st_pred.append('O')\n",
    "    \n",
    "    df['stanford_pred'] = st_pred\n",
    "    \n",
    "    return st_pred, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**NLTK recognizes the following entities:**\n",
    "* ORGANIZATION - Georgia-Pacific Corp., WHO\n",
    "* PERSON - Eddy Bonte, President Obama\n",
    "* LOCATION - Murray River, Mount Everest\n",
    "* DATE - June, 2008-06-29\n",
    "* TIME - two fifty a m, 1:30 p.m.\n",
    "* MONEY - 175 million Canadian Dollars, GBP 10.40\n",
    "* PERCENT - twenty pct, 18.75 %\n",
    "* FACILITY - Washington Monument, Stonehenge\n",
    "* GPE - South East Asia, Midlothian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLTK_pred(dictt, df):\n",
    "    \n",
    "    word_token = word_tokenize(dictt)\n",
    "    tagged_words = pos_tag(word_token)\n",
    "    ne_tagged = ne_chunk(tagged_words, binary = False)\n",
    "\n",
    "    lst_word = []\n",
    "    lst_ne = []\n",
    "\n",
    "    for chunk in ne_tagged:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            if chunk.label() == 'PERSON' or chunk.label() == 'LOCATION' or chunk.label() == 'ORG' or chunk.label() == 'GPE' or chunk.label() == 'MONEY' or chunk.label() == 'DATE':\n",
    "                if chunk.label() == 'ORG':\n",
    "                    lst_word.append(chunk[0][0])\n",
    "                    lst_ne.append('ORGANIZATION')\n",
    "                if chunk.label() == 'LOC' or chunk.label() == 'GPE':\n",
    "                    lst_word.append(chunk[0][0])\n",
    "                    lst_ne.append('LOCATION')\n",
    "                else:\n",
    "                    lst_word.append(chunk[0][0])\n",
    "                    lst_ne.append(chunk.label())\n",
    "    \n",
    "    nltk_pred = []        \n",
    "    check = 0  \n",
    "\n",
    "    for ww in df['word']:\n",
    "        check = 0\n",
    "        for w, n in zip(lst_word, lst_ne):\n",
    "            if ww.__contains__(w):\n",
    "                check = 1\n",
    "                nltk_pred.append(str(n))\n",
    "                break\n",
    "        if check == 0:\n",
    "            nltk_pred.append('O')\n",
    "    \n",
    "    df['nltk_pred'] = nltk_pred\n",
    "    \n",
    "    return nltk_pred, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**spaCy recognizes the following entities:**\n",
    "* PERSON - People, including fictional.\n",
    "* NORP - Nationalities or religious or political groups.\n",
    "* FAC - Buildings, airports, highways, bridges, etc.\n",
    "* ORG - Companies, agencies, institutions, etc.\n",
    "* GPE - Countries, cities, states.\n",
    "* LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "* PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "* EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "* WORK_OF_ART - Titles of books, songs, etc.\n",
    "* LAW - Named documents made into laws.\n",
    "* LANGUAGE - Any named language.\n",
    "* DATE - Absolute or relative dates or periods.\n",
    "* TIME - Times smaller than a day.\n",
    "* PERCENT - Percentage, including ”%“.\n",
    "* MONEY - Monetary values, including unit.\n",
    "* QUANTITY - Measurements, as of weight or distance.\n",
    "* ORDINAL - “first”, “second”, etc.\n",
    "* CARDINAL - Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaCy_pred(dictt, df):\n",
    "    \n",
    "    nlp = en_core_web_sm.load()\n",
    "    # list of words that have named entities\n",
    "    text = ([str(X) for X in nlp(dictt)\n",
    "            if (X.ent_type_ != '' and X.ent_type_ != 'CARDINAL') & (str(X) != 'a') & (str(X) != 'good') & (str(X) != 'day') & (str(X) != '.') & (str(X) != ',')])\n",
    "    # list of named entities\n",
    "    ne = ([X.ent_type_ for X in nlp(dictt)\n",
    "            if (X.ent_type_ != '' and X.ent_type_ != 'CARDINAL') & (str(X) != 'a') & (str(X) != 'good') & (str(X) != 'day') & (str(X) != '.') & (str(X) != ',')])\n",
    "    \n",
    "    sp_pred = []\n",
    "    \n",
    "    for n, i in enumerate(ne):\n",
    "        if i == 'LOC':\n",
    "            ne[n] = 'LOCATION'\n",
    "        if i == 'GPE':\n",
    "            ne[n] = 'LOCATION'\n",
    "        if i == 'ORG':\n",
    "            ne[n] = 'ORGANIZATION'\n",
    "          \n",
    "    check = 0  \n",
    "    \n",
    "    for ww in df['word']:\n",
    "        check = 0\n",
    "        for w, n in zip(text, ne):\n",
    "            if ww.__contains__(w):\n",
    "                check = 1\n",
    "                sp_pred.append(str(n))\n",
    "                break\n",
    "        if check == 0:\n",
    "            sp_pred.append('O')\n",
    "                \n",
    "    df['spacy_pred'] = sp_pred\n",
    "                \n",
    "    return sp_pred, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combing Real Named Entities and Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_models(df):\n",
    "    \n",
    "    # ------------ Selecting same predictions 2 of 3 models ------------\n",
    "    \n",
    "    i_twooth = []\n",
    "    ne_twooth = []\n",
    "\n",
    "    for i, st, nl, sp in zip(df.index, df['stanford_pred'], df['nltk_pred'], df['spacy_pred']):\n",
    "        # check if stanford and nltk are same named entities\n",
    "        if (st != 'O' and nl != 'O') and (str(st) == str(nl)):\n",
    "            i_twooth.append(i)\n",
    "            ne_twooth.append(str(st))\n",
    "        # check if stanford and spacy are same named entities\n",
    "        elif (st != 'O' and sp != 'O') and (str(st) == str(sp)):\n",
    "            i_twooth.append(i)\n",
    "            ne_twooth.append(str(st))\n",
    "        # check if nltk and spacy are same named entities\n",
    "        elif (nl != 'O' and sp != 'O') and (str(nl) == str(sp)):\n",
    "            i_twooth.append(i)\n",
    "            ne_twooth.append(str(nl))\n",
    "        \n",
    "    combined = []\n",
    "    combined_check = 0\n",
    "        \n",
    "    for i in df.index:\n",
    "        combined_check = 0\n",
    "        for ii, n in zip(i_twooth, ne_twooth):\n",
    "            if i == ii:\n",
    "                combined_check = 1\n",
    "                combined.append(str(n))\n",
    "                break\n",
    "        if combined_check == 0:\n",
    "            combined.append('O')\n",
    "       \n",
    "    # ------------ Regular Expression checking ------------\n",
    "    \n",
    "    pii_index = []\n",
    "    pii_type = []\n",
    "    date_check = 0\n",
    "\n",
    "    for i, num in zip(df.index, df['word']):\n",
    "        date_check = 0\n",
    "        for ii in i_twooth:\n",
    "            if i == ii:\n",
    "                date_check = 1\n",
    "                break\n",
    "        if date_check == 0:\n",
    "            # ID card e.g. +666-666-666-6666\n",
    "            if re.search('(\\+?[0-9]{3,}-?[0-9]{3,}-?[0-9]{3,}-?[0-9]{4,})', num):\n",
    "                pii_index.append(i)\n",
    "                pii_type.append('IDCARD')\n",
    "            # phone number e.g. 666-666-6666\n",
    "            elif re.search('(\\+?[0-9]{3,}-?[0-9]{3,}-?[0-9]{4,})', num):\n",
    "                pii_index.append(i)\n",
    "                pii_type.append('PHONENUM')\n",
    "            # account number e.g. 666-666-666\n",
    "            elif re.search('(\\+?[0-9]{3,}-?[0-9]{3,}-?[0-9]{3,})', num):\n",
    "                pii_index.append(i)\n",
    "                pii_type.append('ACCNUM')\n",
    "            # if not has punctuation\n",
    "            elif re.search('[0-9]{9,}', num):\n",
    "                pii_index.append(i)\n",
    "                pii_type.append('PIINUM')\n",
    "            \n",
    "    regex_lst = []\n",
    "    regex_check = 0\n",
    "        \n",
    "    for i in df.index:\n",
    "        regex_check = 0\n",
    "        for ii, pi in zip(pii_index, pii_type):\n",
    "            if i == ii:\n",
    "                regex_check = 1\n",
    "                regex_lst.append(str(pi))\n",
    "                break\n",
    "        if regex_check == 0:\n",
    "            regex_lst.append('O')\n",
    "\n",
    "    # ------------ Combining real ents and regex ------------\n",
    "            \n",
    "    cb_rg = []\n",
    "\n",
    "    for ent, regex in zip(combined, regex_lst):\n",
    "        if ent != 'O' and regex == 'O':\n",
    "            cb_rg.append(ent)\n",
    "        elif regex != 'O' and ent == 'O':\n",
    "            cb_rg.append(regex)\n",
    "        else:\n",
    "            cb_rg.append('O')\n",
    "            \n",
    "    df['real_ents'] = cb_rg\n",
    "    \n",
    "    return cb_rg, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_label = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/ref-nancy-sandra.csv')\n",
    "ref_label = [i for i in ref_label['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_pred, df = Stanford_pred(data['transcript'], df)\n",
    "nltk_pred, df = NLTK_pred(data['transcript'], df)\n",
    "sp_pred, df = spaCy_pred(data['transcript'], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the 3 models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford Accuracy: 90.58%\n",
      "NLTK Accuracy: 85.34%\n",
      "spaCy Accuracy: 91.62%\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.scores import accuracy\n",
    "st_acc = accuracy(ref_label, st_pred)\n",
    "nltk_acc = accuracy(ref_label, nltk_pred)\n",
    "spacy_acc = accuracy(ref_label, sp_pred)\n",
    "\n",
    "print('Stanford Accuracy: %.2f' % (st_acc * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (nltk_acc * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (spacy_acc * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify named entity accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_ENT(ent):\n",
    "    \n",
    "    person = []\n",
    "    org = []\n",
    "    loc = []\n",
    "    cd = []\n",
    "    date = []\n",
    "    money = []\n",
    "    \n",
    "    for p in ent:\n",
    "        if p != 'PERSON':\n",
    "            person.append('O')\n",
    "        else:\n",
    "            person.append(str(p))\n",
    "            \n",
    "    for o in ent:\n",
    "        if o != 'ORGANIZATION':\n",
    "            org.append('O')\n",
    "        else:\n",
    "            org.append(str(o))\n",
    "            \n",
    "    for l in ent:\n",
    "        if l != 'LOCATION':\n",
    "            loc.append('O')\n",
    "        else:\n",
    "            loc.append(str(l))\n",
    "            \n",
    "    for d in ent:\n",
    "        if d != 'DATE':\n",
    "            date.append('O')\n",
    "        else:\n",
    "            date.append(str(d))\n",
    "            \n",
    "    for m in ent:\n",
    "        if m != 'MONEY':\n",
    "            money.append('O')\n",
    "        else:\n",
    "            money.append(str(m))\n",
    "            \n",
    "    return person, org, loc, date, money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_each_ENT(r_ps, r_org, r_loc, r_date, r_money, st_ps, st_org, st_loc, st_date, st_money, nltk_ps, nltk_org, nltk_loc, nltk_date, nltk_money, sp_ps, sp_org, sp_loc, sp_date, sp_money):\n",
    "    \n",
    "    print('-------------------------------------------\\n')\n",
    "    print('PERSON DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_ps, st_ps) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_ps, nltk_ps) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_ps, sp_ps) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('ORGANIZATION DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_org, st_org) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_org, nltk_org) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_org, sp_org) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('LOCATION DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_loc, st_loc) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_loc, nltk_loc) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_loc, sp_loc) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('DATE DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_date, st_date) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_date, nltk_date) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_date, sp_date) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('MONEY DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_money, st_money) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_money, nltk_money) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_money, sp_money) * 100) + '%')\n",
    "    print('\\n-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies of specific named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ps, r_org, r_loc, r_date, r_money = only_ENT(ref_label)\n",
    "st_ps, st_org, st_loc, st_date, st_money = only_ENT(st_pred)\n",
    "nltk_ps, nltk_org, nltk_loc, nltk_date, nltk_money = only_ENT(nltk_pred)\n",
    "sp_ps, sp_org, sp_loc, sp_date, sp_money = only_ENT(sp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "\n",
      "PERSON DETECT ACCURACY:\n",
      "Stanford Accuracy: 98.95%\n",
      "NLTK Accuracy: 93.72%\n",
      "spaCy Accuracy: 98.95%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "ORGANIZATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 97.38%\n",
      "NLTK Accuracy: 98.95%\n",
      "spaCy Accuracy: 97.38%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "LOCATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 96.86%\n",
      "NLTK Accuracy: 95.29%\n",
      "spaCy Accuracy: 96.86%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "CARDINAL NUMBER DETECT ACCURACY:\n",
      "Stanford Accuracy: 96.86%\n",
      "NLTK Accuracy: 96.34%\n",
      "spaCy Accuracy: 97.91%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "DATE DETECT ACCURACY:\n",
      "Stanford Accuracy: 100.00%\n",
      "NLTK Accuracy: 98.43%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "MONEY DETECT ACCURACY:\n",
      "Stanford Accuracy: 100.00%\n",
      "NLTK Accuracy: 100.00%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "acc_each_ENT(r_ps, r_org, r_loc, r_date, r_money, st_ps, st_org, st_loc, st_date, st_money, nltk_ps, nltk_org, nltk_loc, nltk_date, nltk_money, sp_ps, sp_org, sp_loc, sp_date, sp_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>stanford_pred</th>\n",
       "      <th>nltk_pred</th>\n",
       "      <th>spacy_pred</th>\n",
       "      <th>real_ents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello,</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>O</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>called</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virtual</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bank.</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speaking.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  start_time  end_time stanford_pred nltk_pred spacy_pred  \\\n",
       "indx                                                                       \n",
       "0        Hello,         0.1       0.7             O  LOCATION          O   \n",
       "1           you         0.7       1.4             O         O          O   \n",
       "2          have         1.4       1.6             O         O          O   \n",
       "3        called         1.6       2.0             O         O          O   \n",
       "4       virtual         2.0       2.3             O         O          O   \n",
       "5         bank.         2.3       2.6             O         O          O   \n",
       "6          This         2.6       3.3             O         O          O   \n",
       "7            is         3.3       3.5             O         O          O   \n",
       "8         Nancy         3.5       3.9        PERSON    PERSON     PERSON   \n",
       "9     speaking.         3.9       4.4             O         O          O   \n",
       "\n",
       "     real_ents  \n",
       "indx            \n",
       "0            O  \n",
       "1            O  \n",
       "2            O  \n",
       "3            O  \n",
       "4            O  \n",
       "5            O  \n",
       "6            O  \n",
       "7            O  \n",
       "8       PERSON  \n",
       "9            O  "
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_rg, df = combined_models(df)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_ents = df.drop(['stanford_pred', 'nltk_pred', 'spacy_pred'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_ents = formal_ents[formal_ents['real_ents'] != 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>real_ents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ATM</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ATM</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Sandra</td>\n",
       "      <td>31.4</td>\n",
       "      <td>31.8</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>July</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7th.</td>\n",
       "      <td>35.2</td>\n",
       "      <td>35.9</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1974.</td>\n",
       "      <td>35.9</td>\n",
       "      <td>37.4</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>New</td>\n",
       "      <td>43.6</td>\n",
       "      <td>44.3</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>York.</td>\n",
       "      <td>44.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>+558-976-652-3663.</td>\n",
       "      <td>50.4</td>\n",
       "      <td>57.3</td>\n",
       "      <td>IDCARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>+558-976-652-3663.</td>\n",
       "      <td>59.8</td>\n",
       "      <td>63.9</td>\n",
       "      <td>IDCARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ATM</td>\n",
       "      <td>65.9</td>\n",
       "      <td>66.2</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>877-952-6987.</td>\n",
       "      <td>87.4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>877-952-6987.</td>\n",
       "      <td>93.3</td>\n",
       "      <td>96.2</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Nancy.</td>\n",
       "      <td>101.1</td>\n",
       "      <td>101.8</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  start_time  end_time     real_ents\n",
       "indx                                                        \n",
       "8                  Nancy         3.5       3.9        PERSON\n",
       "23                   ATM         9.2       9.7  ORGANIZATION\n",
       "26                   ATM        10.3      10.8  ORGANIZATION\n",
       "62                Sandra        31.4      31.8      LOCATION\n",
       "70                  July        34.0      35.2          DATE\n",
       "71                  7th.        35.2      35.9          DATE\n",
       "72                 1974.        35.9      37.4          DATE\n",
       "82                   New        43.6      44.3      LOCATION\n",
       "83                 York.        44.3      44.3      LOCATION\n",
       "94    +558-976-652-3663.        50.4      57.3        IDCARD\n",
       "98    +558-976-652-3663.        59.8      63.9        IDCARD\n",
       "103                  ATM        65.9      66.2  ORGANIZATION\n",
       "164        877-952-6987.        87.4      91.5      PHONENUM\n",
       "168        877-952-6987.        93.3      96.2      PHONENUM\n",
       "183               Nancy.       101.1     101.8        PERSON"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
