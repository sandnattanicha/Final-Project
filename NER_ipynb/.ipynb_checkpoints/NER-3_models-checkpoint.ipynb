{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Using 3 Models and Rules-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others libraries\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK and Stanford libraries\n",
    "import nltk, re, os\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tree import Tree\n",
    "from nltk import RegexpParser\n",
    "from nltk.chunk.api import ChunkParserI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy libraries\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading json file and storing in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load(path):\n",
    "    # reading json file\n",
    "    with open(path, 'r') as json_file:\n",
    "        f = json.load(json_file)\n",
    "    data = f\n",
    "    \n",
    "    # Collecting index of word, word, start time, and end time\n",
    "    df = pd.DataFrame({'indx': ([X for X in range(len(data['values']['word']))]),\n",
    "                       'word': data['values']['word'], 'start_time': data['values']['start'],\n",
    "                       'end_time': data['values']['end']})\n",
    "    \n",
    "    df = df.set_index('indx')\n",
    "    \n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, df = read_load('D:/DSBA/Project/Final-Project-2/Nancy-Sandra.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello,</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>called</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virtual</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bank.</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speaking.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  start_time  end_time\n",
       "indx                                 \n",
       "0        Hello,         0.1       0.7\n",
       "1           you         0.7       1.4\n",
       "2          have         1.4       1.6\n",
       "3        called         1.6       2.0\n",
       "4       virtual         2.0       2.3\n",
       "5         bank.         2.3       2.6\n",
       "6          This         2.6       3.3\n",
       "7            is         3.3       3.5\n",
       "8         Nancy         3.5       3.9\n",
       "9     speaking.         3.9       4.4"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford NER Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 3 models\n",
    "\n",
    "* 3 classes model for recognizing locations, person, and organizations\n",
    "* 4 classes model for recognizing locations, person, organizations, and miscellaneous entities\n",
    "* 7 classes model for recognizing locations, person, organizations, times, money, percents, and dates\n",
    "\n",
    "In this project, we use 7 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stanford_pred(df):\n",
    "    \n",
    "    st_pred = []\n",
    "    \n",
    "    java_path = (\"C:/Program Files/Java/jdk-15.0.1/bin/java.exe\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "    jar = ('D:/Program/stanford-ner-4.0.0/stanford-ner.jar')\n",
    "    model = ('D:/Program/stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser') # 7 classes\n",
    "    st = StanfordNERTagger(model, jar, encoding = 'utf-8')\n",
    "\n",
    "    classified_text = st.tag(df['word'])\n",
    "\n",
    "    for i in range(len(classified_text)):\n",
    "        if str(classified_text[i][1]) != 'PERSON' and str(classified_text[i][1]) != 'LOCATION' and str(classified_text[i][1]) != 'ORGANIZATION' and str(classified_text[i][1]) != 'MONEY' and str(classified_text[i][1]) != 'DATE':\n",
    "                st_pred.append('O')\n",
    "        else:\n",
    "            st_pred.append(str(classified_text[i][1]))\n",
    "    \n",
    "    df['stanford_pred'] = st_pred\n",
    "    \n",
    "    return st_pred, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLTK recognizes the following entities:**\n",
    "* ORGANIZATION - Georgia-Pacific Corp., WHO\n",
    "* PERSON - Eddy Bonte, President Obama\n",
    "* LOCATION - Murray River, Mount Everest\n",
    "* DATE - June, 2008-06-29\n",
    "* TIME - two fifty a m, 1:30 p.m.\n",
    "* MONEY - 175 million Canadian Dollars, GBP 10.40\n",
    "* PERCENT - twenty pct, 18.75 %\n",
    "* FACILITY - Washington Monument, Stonehenge\n",
    "* GPE - South East Asia, Midlothian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLTK_pred(df):\n",
    "    \n",
    "    tagged_words = pos_tag(df['word'])\n",
    "    ne_tagged = ne_chunk(tagged_words)\n",
    "    # convert prediction to multiline string and then to list (includes pos tags)\n",
    "    multiline_string = nltk.chunk.tree2conllstr(ne_tagged)\n",
    "    multiline_string.split('\\n')\n",
    "    nltk_pred = [i.split(' ')[2] for i in multiline_string.split('\\n')]\n",
    "\n",
    "    # amend class annotations for consistency with reference_annotations\n",
    "    for n, i in enumerate(nltk_pred):\n",
    "        if i == 'B-PERSON':\n",
    "            nltk_pred[n] = 'PERSON'\n",
    "        if i == 'I-PERSON':\n",
    "            nltk_pred[n] = 'PERSON'    \n",
    "        if i == 'B-ORGANIZATION':\n",
    "            nltk_pred[n] = 'ORGANIZATION'\n",
    "        if i == 'I-ORGANIZATION':\n",
    "            nltk_pred[n] = 'ORGANIZATION'\n",
    "        if i == 'B-LOCATION':\n",
    "            nltk_pred[n] = 'LOCATION'\n",
    "        if i == 'I-LOCATION':\n",
    "            nltk_pred[n] = 'LOCATION'\n",
    "        if i == 'B-GPE':\n",
    "            nltk_pred[n] = 'LOCATION'\n",
    "        if i == 'I-GPE':\n",
    "            nltk_pred[n] = 'LOCATION'\n",
    "        if i == 'B-FACILITY':\n",
    "            nltk_pred[n] = 'O'\n",
    "        if i == 'I-FACILITY':\n",
    "            nltk_pred[n] = 'O'\n",
    "        if i == 'B-PERCENT':\n",
    "            nltk_pred[n] = 'O'\n",
    "        if i == 'I-PERCENT':\n",
    "            nltk_pred[n] = 'O'\n",
    "        if i == 'B-TIME':\n",
    "            nltk_pred[n] = 'O'\n",
    "        if i == 'I-TIME':\n",
    "            nltk_pred[n] = 'O'\n",
    "    \n",
    "    df['nltk_pred'] = nltk_pred\n",
    "    \n",
    "    return nltk_pred, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spaCy recognizes the following entities:**\n",
    "* PERSON - People, including fictional.\n",
    "* NORP - Nationalities or religious or political groups.\n",
    "* FAC - Buildings, airports, highways, bridges, etc.\n",
    "* ORG - Companies, agencies, institutions, etc.\n",
    "* GPE - Countries, cities, states.\n",
    "* LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "* PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "* EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "* WORK_OF_ART - Titles of books, songs, etc.\n",
    "* LAW - Named documents made into laws.\n",
    "* LANGUAGE - Any named language.\n",
    "* DATE - Absolute or relative dates or periods.\n",
    "* TIME - Times smaller than a day.\n",
    "* PERCENT - Percentage, including ”%“.\n",
    "* MONEY - Monetary values, including unit.\n",
    "* QUANTITY - Measurements, as of weight or distance.\n",
    "* ORDINAL - “first”, “second”, etc.\n",
    "* CARDINAL - Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaCy_pred(dictt, df):\n",
    "    \n",
    "    nlp = en_core_web_sm.load()\n",
    "    # list of words that have named entities\n",
    "    text = ([str(X) for X in nlp(dictt)\n",
    "            if (X.ent_type_ != '') & (str(X) != 'a') & (str(X) != 'good') & (str(X) != 'day') & (str(X) != '.') & (str(X) != ',')])\n",
    "    # list of named entities\n",
    "    ne = ([X.ent_type_ for X in nlp(dictt)\n",
    "            if (X.ent_type_ != '') & (str(X) != 'a') & (str(X) != 'good') & (str(X) != 'day') & (str(X) != '.') & (str(X) != ',')])\n",
    "    \n",
    "    sp_pred = []\n",
    "    \n",
    "    for n, i in enumerate(ne):\n",
    "        if i == 'LOC':\n",
    "            ne[n] = 'LOCATION'\n",
    "        if i == 'GPE':\n",
    "            ne[n] = 'LOCATION'\n",
    "        if i == 'CARDINAL':\n",
    "            ne[n] = 'CD'\n",
    "        if i == 'ORG':\n",
    "            ne[n] = 'ORGANIZATION'\n",
    "          \n",
    "    check = 0  \n",
    "    \n",
    "    for ww in df['word']:\n",
    "        check = 0\n",
    "        for w, n in zip(text, ne):\n",
    "            if ww.__contains__(w):\n",
    "                check = 1\n",
    "                sp_pred.append(str(n))\n",
    "                break\n",
    "        if check == 0:\n",
    "            sp_pred.append('O')\n",
    "                \n",
    "    df['spacy_pred'] = sp_pred\n",
    "                \n",
    "    return sp_pred, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/word-time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/spacy-ner-tagger.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Hello, you have called Virtual bank, this is Linda speaking. How may I help you?\n",
    "Hi Linda. I was just at your Ville branch and I think I left my Debit card in the ATM machine.\n",
    "Okay. Do you have your Debit card number?\n",
    "I don’t have.\n",
    "Okay, well do you have the checking account number associated with the Debit\n",
    "card? \n",
    "That I do have. Are you ready? I will give you what I have got. 765456789. \n",
    "Okay. That’s 765456789.\n",
    "Correct.\n",
    "What is your identification number?\n",
    "7745896589665.\n",
    "Okay, I have 7745896589665 and what is your name sir? \n",
    "It is Robert Applebaum.\n",
    "Okay. I have Robert Applebaum.\n",
    "Yes.\n",
    "And what is your date of birth Mr. Applebaum?\n",
    "July 7th, 1974. \n",
    "Okay. July 7th, 1974.\n",
    "Yes.\n",
    "And your phone number?\n",
    "It is 6102651715. \n",
    "Okay. I have 6102651715.\n",
    "Yes.\n",
    "Okay Mr. Applebaum. I have just suspended your card. If it is in the machine, we will contact you and lift the suspension. \n",
    "Oh, thank you.\n",
    "Sure. Thank you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlst = []\n",
    "nelst = []\n",
    "\n",
    "for i in range(0, len(tokenized_sent)):\n",
    "    if re.search('phone number', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('PHONENUM')\n",
    "        elif re.search('([0-9]|zero|one|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2])  or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('PHONENUM')\n",
    "    if re.search('account number', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('ACCNUM')\n",
    "        elif re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('ACCNUM')\n",
    "    if re.search('(identify number|identification number)', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('IDCARD')\n",
    "        elif re.search('([0-9]|zero|one|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('IDCARD')\n",
    "\n",
    "pd.DataFrame({'sent': wlst, 'ne': nelst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_label = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/ref-nancy-sandra.csv')\n",
    "ref_label = [i for i in ref_label['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_pred, df = Stanford_pred(df)\n",
    "nltk_pred, df = NLTK_pred(df)\n",
    "sp_pred, df = spaCy_pred(data['transcript'], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/3_MODELS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the 3 models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford Accuracy: 89.01%\n",
      "NLTK Accuracy: 85.34%\n",
      "spaCy Accuracy: 91.62%\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.scores import accuracy\n",
    "st_acc = accuracy(ref_label, st_pred)\n",
    "nltk_acc = accuracy(ref_label, nltk_pred)\n",
    "spacy_acc = accuracy(ref_label, sp_pred)\n",
    "\n",
    "print('Stanford Accuracy: %.2f' % (st_acc * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (nltk_acc * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (spacy_acc * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify named entity accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_ENT(ent):\n",
    "    \n",
    "    person = []\n",
    "    org = []\n",
    "    loc = []\n",
    "    cd = []\n",
    "    date = []\n",
    "    money = []\n",
    "    \n",
    "    for p in ent:\n",
    "        if p != 'PERSON':\n",
    "            person.append('O')\n",
    "        else:\n",
    "            person.append(str(p))\n",
    "            \n",
    "    for o in ent:\n",
    "        if o != 'ORGANIZATION':\n",
    "            org.append('O')\n",
    "        else:\n",
    "            org.append(str(o))\n",
    "            \n",
    "    for l in ent:\n",
    "        if l != 'LOCATION':\n",
    "            loc.append('O')\n",
    "        else:\n",
    "            loc.append(str(l))\n",
    "            \n",
    "    for c in ent:\n",
    "        if c != 'CD':\n",
    "            cd.append('O')\n",
    "        else:\n",
    "            cd.append(str(c))\n",
    "            \n",
    "    for d in ent:\n",
    "        if d != 'DATE':\n",
    "            date.append('O')\n",
    "        else:\n",
    "            date.append(str(d))\n",
    "            \n",
    "    for m in ent:\n",
    "        if m != 'MONEY':\n",
    "            money.append('O')\n",
    "        else:\n",
    "            money.append(str(m))\n",
    "            \n",
    "    return person, org, loc, cd, date, money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def acc_each_ENT(r_ps, r_org, r_loc, r_cd, r_date, r_money, st_ps, st_org, st_loc, st_cd, st_date, st_money, nltk_ps, nltk_org, nltk_loc, nltk_cd, nltk_date, nltk_money, sp_ps, sp_org, sp_loc, sp_cd, sp_date, sp_money):\n",
    "    \n",
    "    print('-------------------------------------------\\n')\n",
    "    print('PERSON DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_ps, st_ps) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_ps, nltk_ps) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_ps, sp_ps) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('ORGANIZATION DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_org, st_org) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_org, nltk_org) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_org, sp_org) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('LOCATION DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_loc, st_loc) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_loc, nltk_loc) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_loc, sp_loc) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('CARDINAL NUMBER DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_cd, st_cd) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_cd, nltk_cd) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_cd, sp_cd) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('DATE DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_date, st_date) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_date, nltk_date) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_date, sp_date) * 100) + '%')\n",
    "    print('\\n-------------------------------------------\\n')\n",
    "\n",
    "    print('MONEY DETECT ACCURACY:')\n",
    "    print('Stanford Accuracy: %.2f' % (accuracy(r_money, st_money) * 100) + '%')\n",
    "    print('NLTK Accuracy: %.2f' % (accuracy(r_money, nltk_money) * 100) + '%')\n",
    "    print('spaCy Accuracy: %.2f' % (accuracy(r_money, sp_money) * 100) + '%')\n",
    "    print('\\n-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies of specific named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ps, r_org, r_loc, r_cd, r_date, r_money = only_ENT(ref_label)\n",
    "st_ps, st_org, st_loc, st_cd, st_date, st_money = only_ENT(st_pred)\n",
    "nltk_ps, nltk_org, nltk_loc, nltk_cd, nltk_date, nltk_money = only_ENT(nltk_pred)\n",
    "sp_ps, sp_org, sp_loc, sp_cd, sp_date, sp_money = only_ENT(sp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "\n",
      "PERSON DETECT ACCURACY:\n",
      "Stanford Accuracy: 97.91%\n",
      "NLTK Accuracy: 96.86%\n",
      "spaCy Accuracy: 98.95%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "ORGANIZATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 97.38%\n",
      "NLTK Accuracy: 97.38%\n",
      "spaCy Accuracy: 97.38%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "LOCATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 96.34%\n",
      "NLTK Accuracy: 94.76%\n",
      "spaCy Accuracy: 96.86%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "CARDINAL NUMBER DETECT ACCURACY:\n",
      "Stanford Accuracy: 96.86%\n",
      "NLTK Accuracy: 96.86%\n",
      "spaCy Accuracy: 97.91%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "DATE DETECT ACCURACY:\n",
      "Stanford Accuracy: 100.00%\n",
      "NLTK Accuracy: 98.43%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "MONEY DETECT ACCURACY:\n",
      "Stanford Accuracy: 100.00%\n",
      "NLTK Accuracy: 100.00%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "acc_each_ENT(r_ps, r_org, r_loc, r_cd, r_date, r_money, st_ps, st_org, st_loc, st_cd, st_date, st_money, nltk_ps, nltk_org, nltk_loc, nltk_cd, nltk_date, nltk_money, sp_ps, sp_org, sp_loc, sp_cd, sp_date, sp_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation that has money named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2, df2 = read_load('D:/DSBA/Project/Final-Project-2/dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_pred2, df2 = Stanford_pred(df2)\n",
    "nltk_pred2, df2 = NLTK_pred(df2)\n",
    "sp_pred2, df2 = spaCy_pred(data2['transcript'], df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_label2 = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/ref_label.csv')\n",
    "ref_label2 = [i for i in ref_label2['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ps2, r_org2, r_loc2, r_cd2, r_date2, r_money2 = only_ENT(ref_label2)\n",
    "st_ps2, st_org2, st_loc2, st_cd2, st_date2, st_money2 = only_ENT(st_pred2)\n",
    "nltk_ps2, nltk_org2, nltk_loc2, nltk_cd2, nltk_date2, nltk_money2 = only_ENT(nltk_pred2)\n",
    "sp_ps2, sp_org2, sp_loc2, sp_cd2, sp_date2, sp_money2 = only_ENT(sp_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford Accuracy: 91.87%\n",
      "NLTK Accuracy: 91.06%\n",
      "spaCy Accuracy: 93.50%\n"
     ]
    }
   ],
   "source": [
    "st_acc2 = accuracy(ref_label2, st_pred2)\n",
    "nltk_acc2 = accuracy(ref_label2, nltk_pred2)\n",
    "spacy_acc2 = accuracy(ref_label2, sp_pred2)\n",
    "\n",
    "print('Stanford Accuracy: %.2f' % (st_acc2 * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (nltk_acc2 * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (spacy_acc2 * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "\n",
      "PERSON DETECT ACCURACY:\n",
      "Stanford Accuracy: 96.75%\n",
      "NLTK Accuracy: 97.56%\n",
      "spaCy Accuracy: 98.37%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "ORGANIZATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 100.00%\n",
      "NLTK Accuracy: 99.19%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "LOCATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 98.37%\n",
      "NLTK Accuracy: 98.37%\n",
      "spaCy Accuracy: 98.37%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "CARDINAL NUMBER DETECT ACCURACY:\n",
      "Stanford Accuracy: 100.00%\n",
      "NLTK Accuracy: 100.00%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "DATE DETECT ACCURACY:\n",
      "Stanford Accuracy: 97.56%\n",
      "NLTK Accuracy: 95.93%\n",
      "spaCy Accuracy: 96.75%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "MONEY DETECT ACCURACY:\n",
      "Stanford Accuracy: 99.19%\n",
      "NLTK Accuracy: 99.19%\n",
      "spaCy Accuracy: 100.00%\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "acc_each_ENT(r_ps2, r_org2, r_loc2, r_cd2, r_date2, r_money2, st_ps2, st_org2, st_loc2, st_cd2, st_date2, st_money2, nltk_ps2, nltk_org2, nltk_loc2, nltk_cd2, nltk_date2, nltk_money2, sp_ps2, sp_org2, sp_loc2, sp_cd2, sp_date2, sp_money2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
