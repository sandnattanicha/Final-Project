{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Using 3 Models and Rules-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others libraries\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK and Stanford libraries\n",
    "import nltk, re, os\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tree import Tree\n",
    "from nltk import RegexpParser\n",
    "from nltk.chunk.api import ChunkParserI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy libraries\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading json file and storing in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load(path):\n",
    "    # reading json file\n",
    "    with open(path, 'r') as json_file:\n",
    "        f = json.load(json_file)\n",
    "    data = f\n",
    "    \n",
    "    # Collecting index of word, word, start time, and end time\n",
    "    df = pd.DataFrame({'count': ([X for X in range(len(data['values']['word']))]),\n",
    "                       'word': data['values']['word'], 'start_time': data['values']['start'],\n",
    "                       'end_time': data['values']['end']})\n",
    "    \n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford NER Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 3 models\n",
    "\n",
    "* 3 classes model for recognizing locations, person, and organizations\n",
    "* 4 classes model for recognizing locations, person, organizations, and miscellaneous entities\n",
    "* 7 classes model for recognizing locations, person, organizations, times, money, percents, and dates\n",
    "\n",
    "In this project, we use 7 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanford_tagger(document):\n",
    "    lst_word = []\n",
    "    lst_ne = []\n",
    "    lst_count = []\n",
    "\n",
    "    java_path = (\"C:/Program Files/Java/jdk-15.0.1/bin/java.exe\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "    jar = ('D:/Program/stanford-ner-4.0.0/stanford-ner.jar')\n",
    "    model = ('D:/Program/stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser') # 7 classes\n",
    "    st = StanfordNERTagger(model, jar, encoding = 'utf-8')\n",
    "    \n",
    "    # word_token = word_tokenize(document)\n",
    "    classified_text = st.tag(document['word'])\n",
    "    \n",
    "    for i in range(len(classified_text)):\n",
    "        if str(classified_text[i][1]) != 'O':\n",
    "            lst_word.append(str(classified_text[i][0]))\n",
    "            lst_ne.append(str(classified_text[i][1]))\n",
    "            lst_count.append(i)\n",
    "    st_df = pd.DataFrame({'count': lst_count,'word': lst_word, 'stanford_ne': lst_ne})\n",
    "\n",
    "    return st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>stanford_ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>speaking.</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>December</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2019</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       word stanford_ne\n",
       "0      8      Sarah      PERSON\n",
       "1      9  speaking.      PERSON\n",
       "2     49   December        DATE\n",
       "3     50       2019        DATE\n",
       "4     72        Amy      PERSON\n",
       "5     73      Gough      PERSON\n",
       "6     74      Gough      PERSON"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_df = stanford_tagger(df)\n",
    "st_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLTK recognizes the following entities:**\n",
    "* ORGANIZATION - Georgia-Pacific Corp., WHO\n",
    "* PERSON - Eddy Bonte, President Obama\n",
    "* LOCATION - Murray River, Mount Everest\n",
    "* DATE - June, 2008-06-29\n",
    "* TIME - two fifty a m, 1:30 p.m.\n",
    "* MONEY - 175 million Canadian Dollars, GBP 10.40\n",
    "* PERCENT - twenty pct, 18.75 %\n",
    "* FACILITY - Washington Monument, Stonehenge\n",
    "* GPE - South East Asia, Midlothian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tagger(document):\n",
    "    lst_word = []\n",
    "    lst_ne = []\n",
    "    lst_count = []\n",
    "    \n",
    "    # word_token = word_tokenize(document)\n",
    "    tagged_words = pos_tag(document['word'])\n",
    "    ne_tagged = ne_chunk(tagged_words, binary = False) # False for details NE type\n",
    "    # ne_tagged.draw()\n",
    "    \n",
    "    for chunk in range(len(ne_tagged)):\n",
    "        if hasattr(ne_tagged[chunk], 'label'):\n",
    "            lst_word.append(str(ne_tagged[chunk][0][0]))\n",
    "            lst_ne.append(str(ne_tagged[chunk].label()))\n",
    "            lst_count.append(chunk)\n",
    "        if not hasattr(ne_tagged[chunk], 'label'):\n",
    "            if str(ne_tagged[chunk][0:][1:][0]) == 'CD':\n",
    "                lst_word.append(str(ne_tagged[chunk][0]))\n",
    "                lst_ne.append(str(ne_tagged[chunk][0:][1:][0]))\n",
    "                lst_count.append(chunk)\n",
    "            \n",
    "    nltk_df = pd.DataFrame({'count': lst_count, 'word': lst_word, 'nltk_ne': lst_ne})\n",
    "    \n",
    "    return nltk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>nltk_ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>Hey</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>2nd</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2019</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89</td>\n",
       "      <td>Mega</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count   word       nltk_ne\n",
       "0      8  Sarah        PERSON\n",
       "1     15    Hey        PERSON\n",
       "2     47    2nd            CD\n",
       "3     50   2019            CD\n",
       "4     66    Amy        PERSON\n",
       "5     72    Amy        PERSON\n",
       "6     89   Mega  ORGANIZATION\n",
       "7    130    Yes        PERSON"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_df = nltk_tagger(df)\n",
    "nltk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spaCy recognizes the following entities:**\n",
    "* PERSON - People, including fictional.\n",
    "* NORP - Nationalities or religious or political groups.\n",
    "* FAC - Buildings, airports, highways, bridges, etc.\n",
    "* ORG - Companies, agencies, institutions, etc.\n",
    "* GPE - Countries, cities, states.\n",
    "* LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "* PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "* EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "* WORK_OF_ART - Titles of books, songs, etc.\n",
    "* LAW - Named documents made into laws.\n",
    "* LANGUAGE - Any named language.\n",
    "* DATE - Absolute or relative dates or periods.\n",
    "* TIME - Times smaller than a day.\n",
    "* PERCENT - Percentage, including ”%“.\n",
    "* MONEY - Monetary values, including unit.\n",
    "* QUANTITY - Measurements, as of weight or distance.\n",
    "* ORDINAL - “first”, “second”, etc.\n",
    "* CARDINAL - Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # replace . and a space with only a space\n",
    "    text = text.replace(\".\", \"\").replace(\",\", \"\").replace(\"?\", \"\").replace(\"$\", \"\").replace(\"\\'\", \"\")\n",
    "    # get rid of the . at the end of each line. \n",
    "    cleaned_text = re.sub(\"\\.$\", \"\", text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def spaCy_tagger(document):\n",
    "    new_words = []\n",
    "    new_tokens = []\n",
    "    count = []\n",
    "    \n",
    "    nlp = en_core_web_sm.load()\n",
    "    doc = nlp(clean_text(document))\n",
    "    \n",
    "    for token in range(len(doc)):\n",
    "        if doc[token].ent_type_ != '':\n",
    "            if doc[token].ent_type_ == 'DATE':\n",
    "                if (doc[token].text != 'a') and (doc[token].text != 'good') and (doc[token].text != 'day'):\n",
    "                    new_words.append(doc[token].text)\n",
    "                    new_tokens.append(doc[token].ent_type_)\n",
    "                    count.append(token)\n",
    "            elif doc[token].ent_type_ == 'GPE' or doc[token].ent_type_ == 'LOC':\n",
    "                new_words.append(doc[token].text)\n",
    "                new_tokens.append('LOCATION')\n",
    "                count.append(token)\n",
    "            elif doc[token].ent_type_ == 'ORG':\n",
    "                new_words.append(doc[token].text)\n",
    "                new_tokens.append('ORGANIZATION')\n",
    "                count.append(token)\n",
    "            else:\n",
    "                new_words.append(doc[token].text)\n",
    "                new_tokens.append(doc[token].ent_type_)\n",
    "                count.append(token)\n",
    "     \n",
    "    spc_df = pd.DataFrame({'count': count, 'word': new_words, 'spacy_ne': new_tokens})\n",
    "    \n",
    "    return spc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>spacy_ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>the</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>2nd</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>of</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>December</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>2019</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>Amy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74</td>\n",
       "      <td>Gough</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      word spacy_ne\n",
       "0      8     Sarah   PERSON\n",
       "1     46       the     DATE\n",
       "2     47       2nd     DATE\n",
       "3     48        of     DATE\n",
       "4     49  December     DATE\n",
       "5     50      2019     DATE\n",
       "6     66       Amy   PERSON\n",
       "7     72       Amy   PERSON\n",
       "8     73     Gough   PERSON\n",
       "9     74     Gough   PERSON"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spc_df = spaCy_tagger(data['transcript'])\n",
    "spc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/word-time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/spacy-ner-tagger.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Hello, you have called Virtual bank, this is Linda speaking. How may I help you?\n",
    "Hi Linda. I was just at your Ville branch and I think I left my Debit card in the ATM machine.\n",
    "Okay. Do you have your Debit card number?\n",
    "I don’t have.\n",
    "Okay, well do you have the checking account number associated with the Debit\n",
    "card? \n",
    "That I do have. Are you ready? I will give you what I have got. 765456789. \n",
    "Okay. That’s 765456789.\n",
    "Correct.\n",
    "What is your identification number?\n",
    "7745896589665.\n",
    "Okay, I have 7745896589665 and what is your name sir? \n",
    "It is Robert Applebaum.\n",
    "Okay. I have Robert Applebaum.\n",
    "Yes.\n",
    "And what is your date of birth Mr. Applebaum?\n",
    "July 7th, 1974. \n",
    "Okay. July 7th, 1974.\n",
    "Yes.\n",
    "And your phone number?\n",
    "It is 6102651715. \n",
    "Okay. I have 6102651715.\n",
    "Yes.\n",
    "Okay Mr. Applebaum. I have just suspended your card. If it is in the machine, we will contact you and lift the suspension. \n",
    "Oh, thank you.\n",
    "Sure. Thank you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>ne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't use my old phone number anymore, but ...</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's one one one five four four two two two?</td>\n",
       "      <td>ACCNUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My identification number is 1 1 0 2 5 6 9 8 5 ...</td>\n",
       "      <td>IDCARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Five four two 9800 11-2.</td>\n",
       "      <td>IDCARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My phone number is seven.</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seven one nine eight five five five eight seven.</td>\n",
       "      <td>PHONENUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent        ne\n",
       "0  I didn't use my old phone number anymore, but ...  PHONENUM\n",
       "1     That's one one one five four four two two two?    ACCNUM\n",
       "2  My identification number is 1 1 0 2 5 6 9 8 5 ...    IDCARD\n",
       "3                           Five four two 9800 11-2.    IDCARD\n",
       "4                          My phone number is seven.  PHONENUM\n",
       "5   Seven one nine eight five five five eight seven.  PHONENUM"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlst = []\n",
    "nelst = []\n",
    "\n",
    "for i in range(0, len(tokenized_sent)):\n",
    "    if re.search('phone number', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('PHONENUM')\n",
    "        elif re.search('([0-9]|zero|one|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2])  or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('PHONENUM')\n",
    "    if re.search('account number', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('ACCNUM')\n",
    "        elif re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('ACCNUM')\n",
    "    if re.search('(identify number|identification number)', tokenized_sent[i]):\n",
    "        if re.search('([0-9]|zero|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+1]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+1]):\n",
    "            wlst.append(str(tokenized_sent[i+1]))\n",
    "            nelst.append('IDCARD')\n",
    "        elif re.search('([0-9]|zero|one|two|three|four|five|six|seven|eight|nine)+', tokenized_sent[i+2]) or re.search(r'(\\bone\\b)+', tokenized_sent[i+2]):\n",
    "            wlst.append(str(tokenized_sent[i+2]))\n",
    "            nelst.append('IDCARD')\n",
    "\n",
    "pd.DataFrame({'sent': wlst, 'ne': nelst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, df = read_load('D:/DSBA/Project/Final-Project-2/Nancy-Sandra.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/DSBA/Project/Final-Project-2/data/Text files/word-time1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virtual</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bank.</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speaking.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word         label\n",
       "0     Hello,             O\n",
       "1        you             O\n",
       "2       have             O\n",
       "3     called             O\n",
       "4    virtual  ORGANIZATION\n",
       "5      bank.  ORGANIZATION\n",
       "6       This             O\n",
       "7         is             O\n",
       "8      Nancy        PERSON\n",
       "9  speaking.             O"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_label = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/ref-nancy-sandra.csv')\n",
    "ref_label.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stanford prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanford_pred(document):\n",
    "    \n",
    "    java_path = (\"C:/Program Files/Java/jdk-15.0.1/bin/java.exe\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "    jar = ('D:/Program/stanford-ner-4.0.0/stanford-ner.jar')\n",
    "    model = ('D:/Program/stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser') # 7 classes\n",
    "    st = StanfordNERTagger(model, jar, encoding = 'utf-8')\n",
    "\n",
    "    classified_text = st.tag(df['word'])\n",
    "\n",
    "    st_pred = []\n",
    "\n",
    "    for i in range(len(classified_text)):\n",
    "        st_pred.append(str(classified_text[i][1]))\n",
    "    \n",
    "    return st_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_pred = stanford_pred(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLTK prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLTK_pred(document):\n",
    "    \n",
    "    tagged_words = pos_tag(document['word'])\n",
    "    ne_tagged = ne_chunk(tagged_words)\n",
    "    # convert prediction to multiline string and then to list (includes pos tags)\n",
    "    multiline_string = nltk.chunk.tree2conllstr(ne_tagged)\n",
    "    multiline_string.split(\"\\n\")\n",
    "    nltk_pred = [i.split(\" \")[2] for i in multiline_string.split(\"\\n\")]\n",
    "\n",
    "    # amend class annotations for consistency with reference_annotations\n",
    "    for n,i in enumerate(nltk_pred):\n",
    "        if i == \"B-PERSON\":\n",
    "            nltk_pred[n] = \"PERSON\"\n",
    "        if i == \"I-PERSON\":\n",
    "            nltk_pred[n] = \"PERSON\"    \n",
    "        if i == \"B-ORGANIZATION\":\n",
    "            nltk_pred[n] = \"ORGANIZATION\"\n",
    "        if i == \"I-ORGANIZATION\":\n",
    "            nltk_pred[n] = \"ORGANIZATION\"\n",
    "        if i == \"B-LOCATION\":\n",
    "            nltk_pred[n] = \"LOCATION\"\n",
    "        if i == \"I-LOCATION\":\n",
    "            nltk_pred[n] = \"LOCATION\"\n",
    "        if i == \"B-GPE\":\n",
    "            nltk_pred[n] = \"LOCATION\"\n",
    "        if i == \"I-GPE\":\n",
    "            nltk_pred[n] = \"LOCATION\"\n",
    "    \n",
    "    return nltk_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_pred = NLTK_pred(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spaCy prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaCy_pred(document):\n",
    "    new_words = []\n",
    "    new_tokens = []\n",
    "    count = []\n",
    "    \n",
    "    # replace . and a space with only a space\n",
    "    document = document.replace(\".\", \"\").replace(\",\", \"\").replace(\"?\", \"\").replace(\"$\", \"\").replace(\"\\'\", \"\")\n",
    "    # get rid of the . at the end of each line.\n",
    "    cleaned_text = re.sub(\"\\.$\", \"\", document)\n",
    "    \n",
    "    nlp = en_core_web_sm.load()\n",
    "    doc = nlp(cleaned_text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.ent_type_ != '':\n",
    "            if token.ent_type_ == 'DATE':\n",
    "                if (token.text != 'a') and (token.text != 'good') and (token.text != 'day'):\n",
    "                    new_tokens.append(token.ent_type_)\n",
    "                else:\n",
    "                    new_tokens.append('O')\n",
    "            elif token.ent_type_ == 'CARDINAL':\n",
    "                new_tokens.append('CD')\n",
    "            elif token.ent_type_ == 'GPE' or token.ent_type_ == 'LOC':\n",
    "                new_tokens.append('LOCATION')\n",
    "            elif token.ent_type_ == 'ORG':\n",
    "                new_tokens.append('ORGANIZATION')\n",
    "            else:\n",
    "                new_tokens.append(token.ent_type_)\n",
    "        elif token.ent_type_ == '':\n",
    "            new_tokens.append('O')\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_pred = spaCy_pred(data['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_pred = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/spacy-pred-nancy-sandra.csv')\n",
    "spacy_pred = spacy_pred['spacy_label']\n",
    "spacy_pred = [x for x in spacy_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the 3 models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford Accuracy: 89.01%\n",
      "NLTK Accuracy: 85.34%\n",
      "spaCy Accuracy: 91.10%\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.scores import accuracy\n",
    "st_acc = accuracy(ref_label['label'], st_pred)\n",
    "nltk_acc = accuracy(ref_label['label'], nltk_pred)\n",
    "spacy_acc = accuracy(ref_label['label'], spacy_pred)\n",
    "\n",
    "print('Stanford Accuracy: %.2f' % (st_acc * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (nltk_acc * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (spacy_acc * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify named entity accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_PERSON(person):\n",
    "    for n,i in enumerate(person):\n",
    "        if i != \"PERSON\":\n",
    "            person[n] = \"O\"\n",
    "    \n",
    "    return person\n",
    "\n",
    "def only_ORG(org):\n",
    "    for n,i in enumerate(org):\n",
    "        if i != \"ORGANIZATION\":\n",
    "            org[n] = \"O\"\n",
    "    \n",
    "    return org\n",
    "\n",
    "def only_LOC(loc):\n",
    "    for n,i in enumerate(loc):\n",
    "        if i != \"LOCATION\":\n",
    "            loc[n] = \"O\"\n",
    "    \n",
    "    return loc\n",
    "\n",
    "def only_CD(cd):\n",
    "    for n,i in enumerate(cd):\n",
    "        if i != \"CD\":\n",
    "            cd[n] = \"O\"\n",
    "    \n",
    "    return cd\n",
    "\n",
    "def only_DATE(date):\n",
    "    for n,i in enumerate(date):\n",
    "        if i != \"DATE\":\n",
    "            date[n] = \"O\"\n",
    "    \n",
    "    return date\n",
    "\n",
    "def only_MONEY(money):\n",
    "    for n,i in enumerate(money):\n",
    "        if i != \"MONEY\":\n",
    "            money[n] = \"O\"\n",
    "    \n",
    "    return money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DETECT ACCURACIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford Accuracy: 97.91%\n",
      "NLTK Accuracy: 97.91%\n",
      "spaCy Accuracy: 97.91%\n"
     ]
    }
   ],
   "source": [
    "print('Stanford Accuracy: %.2f' % (accuracy(only_PERSON([x for x in ref_label['label']]), only_PERSON(st_pred)) * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (accuracy(only_PERSON([x for x in ref_label['label']]), only_PERSON(nltk_pred)) * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (accuracy(only_PERSON([x for x in ref_label['label']]), only_PERSON(spacy_pred)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------\n",
      "\n",
      "PERSON DETECT ACCURACY:\n",
      "Stanford Accuracy: 97.91%\n",
      "NLTK Accuracy: 97.91%\n",
      "spaCy Accuracy: 97.91%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "ORGANIZATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 98.95%\n",
      "NLTK Accuracy: 98.95%\n",
      "spaCy Accuracy: 98.95%\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "LOCATION DETECT ACCURACY:\n",
      "Stanford Accuracy: 95.81%\n",
      "NLTK Accuracy: 95.81%\n",
      "spaCy Accuracy: 95.81%\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n-------------------------------------------\\n')\n",
    "print('PERSON DETECT ACCURACY:')\n",
    "print('Stanford Accuracy: %.2f' % (accuracy(only_PERSON([x for x in ref_label['label']]), only_PERSON(st_pred)) * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (accuracy(only_PERSON([x for x in ref_label['label']]), only_PERSON(nltk_pred)) * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (accuracy(only_PERSON([x for x in ref_label['label']]), only_PERSON(spacy_pred)) * 100) + '%')\n",
    "print('\\n-------------------------------------------\\n')\n",
    "\n",
    "print('ORGANIZATION DETECT ACCURACY:')\n",
    "print('Stanford Accuracy: %.2f' % (accuracy(only_ORG([x for x in ref_label['label']]), only_ORG(st_pred)) * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (accuracy(only_ORG([x for x in ref_label['label']]), only_ORG(nltk_pred)) * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (accuracy(only_ORG([x for x in ref_label['label']]), only_ORG(spacy_pred)) * 100) + '%')\n",
    "print('\\n-------------------------------------------\\n')\n",
    "\n",
    "print('LOCATION DETECT ACCURACY:')\n",
    "print('Stanford Accuracy: %.2f' % (accuracy(only_LOC([x for x in ref_label['label']]), only_LOC(st_pred)) * 100) + '%')\n",
    "print('NLTK Accuracy: %.2f' % (accuracy(only_LOC([x for x in ref_label['label']]), only_LOC(nltk_pred)) * 100) + '%')\n",
    "print('spaCy Accuracy: %.2f' % (accuracy(only_LOC([x for x in ref_label['label']]), only_LOC(spacy_pred)) * 100) + '%')\n",
    "print('\\n-------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Nancy', 'PERSON'), ('ATM', 'ORG'), ('ATM', 'ORG'), ('111', 'CARDINAL'), ('July', 'DATE'), ('7th', 'DATE'), ('.', 'DATE'), ('1974', 'DATE'), ('132', 'CARDINAL'), ('New', 'GPE'), ('York', 'GPE'), ('ATM', 'ORG'), ('877', 'CARDINAL'), ('877', 'CARDINAL'), ('Nancy', 'PERSON'), ('a', 'DATE'), ('good', 'DATE'), ('day', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print([(x.text, x.ent_type_) for x in nlp(data['transcript']) if x.ent_type_ != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Nancy', 'PERSON'), ('ATM', 'ORG'), ('ATM', 'ORG'), ('111', 'CARDINAL'), ('July 7th.', 'DATE'), ('1974', 'DATE'), ('132', 'CARDINAL'), ('New York', 'GPE'), ('ATM', 'ORG'), ('877', 'CARDINAL'), ('877', 'CARDINAL'), ('Nancy', 'PERSON'), ('a good day', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print([(str(x), x.label_) for x in nlp(data['transcript']).ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Hello, 'O', ''),\n",
      " (you, 'O', ''),\n",
      " (have, 'O', ''),\n",
      " (called, 'O', ''),\n",
      " (virtual, 'O', ''),\n",
      " (bank, 'O', ''),\n",
      " (This, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (Nancy, 'O', ''),\n",
      " (speaking, 'O', ''),\n",
      " (How, 'O', ''),\n",
      " (may, 'O', ''),\n",
      " (I, 'O', ''),\n",
      " (help, 'O', ''),\n",
      " (you, 'O', ''),\n",
      " (I, 'O', ''),\n",
      " (just, 'O', ''),\n",
      " (had, 'O', ''),\n",
      " (withdrawn, 'O', ''),\n",
      " (some, 'O', ''),\n",
      " (cash, 'O', ''),\n",
      " (from, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (ATM, 'B', 'ORG'),\n",
      " (machine, 'O', ''),\n",
      " (and, 'O', ''),\n",
      " (ATM, 'B', 'ORG'),\n",
      " (transaction, 'O', ''),\n",
      " (failed, 'O', ''),\n",
      " (but, 'O', ''),\n",
      " (money, 'O', ''),\n",
      " (got, 'O', ''),\n",
      " (debited, 'O', ''),\n",
      " (Can, 'O', ''),\n",
      " (you, 'O', ''),\n",
      " (fix, 'O', ''),\n",
      " (this, 'O', ''),\n",
      " (problem, 'O', ''),\n",
      " (Sure, 'O', ''),\n",
      " (What, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (account, 'O', ''),\n",
      " (number, 'O', ''),\n",
      " (It, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (111, 'B', 'CARDINAL'),\n",
      " (to, 'O', ''),\n",
      " (36669, 'O', ''),\n",
      " (Just, 'O', ''),\n",
      " (a, 'O', ''),\n",
      " (moment, 'O', ''),\n",
      " (Okay, 'O', ''),\n",
      " (And, 'O', ''),\n",
      " (what, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (name, 'O', ''),\n",
      " (maam, 'O', ''),\n",
      " (My, 'O', ''),\n",
      " (name, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (Sandra, 'O', ''),\n",
      " (read, 'O', ''),\n",
      " (and, 'O', ''),\n",
      " (what, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (birthday, 'O', ''),\n",
      " (man, 'O', ''),\n",
      " (July, 'B', 'DATE'),\n",
      " (7th, 'I', 'DATE'),\n",
      " (1974, 'I', 'DATE'),\n",
      " (Okay, 'O', ''),\n",
      " (What, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (address, 'O', ''),\n",
      " (132, 'B', 'CARDINAL'),\n",
      " (my, 'O', ''),\n",
      " (Street, 'O', ''),\n",
      " (Kingston, 'O', ''),\n",
      " (New, 'O', ''),\n",
      " (York, 'O', ''),\n",
      " (Okay, 'O', ''),\n",
      " (Miss, 'O', ''),\n",
      " (read, 'O', ''),\n",
      " (can, 'O', ''),\n",
      " (I, 'O', ''),\n",
      " (have, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (identify, 'O', ''),\n",
      " (number, 'O', ''),\n",
      " (Okay, 'O', ''),\n",
      " (+558, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (976, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (652, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (3663, 'O', ''),\n",
      " (Okay, 'O', ''),\n",
      " (I, 'O', ''),\n",
      " (have, 'O', ''),\n",
      " (+558, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (976, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (652, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (3663, 'O', ''),\n",
      " (Correct, 'O', ''),\n",
      " (Where, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (ATM, 'B', 'ORG'),\n",
      " (machine, 'O', ''),\n",
      " (that, 'O', ''),\n",
      " (you, 'O', ''),\n",
      " (had, 'O', ''),\n",
      " (withdrawn, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (cash, 'O', ''),\n",
      " (I, 'O', ''),\n",
      " (do, 'O', ''),\n",
      " (not, 'O', ''),\n",
      " (know, 'O', ''),\n",
      " (where, 'O', ''),\n",
      " (exactly, 'O', ''),\n",
      " (it, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (Its, 'O', ''),\n",
      " (somewhere, 'O', ''),\n",
      " (on, 'O', ''),\n",
      " (my, 'O', ''),\n",
      " (street, 'O', ''),\n",
      " (That, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (fine, 'O', ''),\n",
      " (We, 'O', ''),\n",
      " (will, 'O', ''),\n",
      " (check, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (withdrawal, 'O', ''),\n",
      " (transaction, 'O', ''),\n",
      " (and, 'O', ''),\n",
      " (we, 'O', ''),\n",
      " (will, 'O', ''),\n",
      " (refund, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (money, 'O', ''),\n",
      " (to, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (account, 'O', ''),\n",
      " (Do, 'O', ''),\n",
      " (you, 'O', ''),\n",
      " (want, 'O', ''),\n",
      " (to, 'O', ''),\n",
      " (receive, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (message, 'O', ''),\n",
      " (when, 'O', ''),\n",
      " (we, 'O', ''),\n",
      " (are, 'O', ''),\n",
      " (refunding, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (money, 'O', ''),\n",
      " (Yes, 'O', ''),\n",
      " (please, 'O', ''),\n",
      " (Okay, 'O', ''),\n",
      " (What, 'O', ''),\n",
      " (is, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (phone, 'O', ''),\n",
      " (number, 'O', ''),\n",
      " (man, 'O', ''),\n",
      " (877, 'B', 'CARDINAL'),\n",
      " (-, 'O', ''),\n",
      " (952, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (6987, 'O', ''),\n",
      " (Okay, 'O', ''),\n",
      " (I, 'O', ''),\n",
      " (have, 'O', ''),\n",
      " (877, 'B', 'CARDINAL'),\n",
      " (-, 'O', ''),\n",
      " (952, 'O', ''),\n",
      " (-, 'O', ''),\n",
      " (6987, 'O', ''),\n",
      " (We, 'O', ''),\n",
      " (will, 'O', ''),\n",
      " (send, 'O', ''),\n",
      " (a, 'O', ''),\n",
      " (message, 'O', ''),\n",
      " (when, 'O', ''),\n",
      " (we, 'O', ''),\n",
      " (refund, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (money, 'O', ''),\n",
      " (to, 'O', ''),\n",
      " (your, 'O', ''),\n",
      " (account, 'O', ''),\n",
      " (Thanks, 'O', ''),\n",
      " (Nancy, 'B', 'PERSON'),\n",
      " (Have, 'O', ''),\n",
      " (a, 'O', ''),\n",
      " (good, 'O', ''),\n",
      " (day, 'O', ''),\n",
      " (man, 'O', ''),\n",
      " (Thank, 'O', ''),\n",
      " (you, 'O', '')]\n"
     ]
    }
   ],
   "source": [
    "pprint([(X, X.ent_iob_, X.ent_type_) for X in nlp(test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
