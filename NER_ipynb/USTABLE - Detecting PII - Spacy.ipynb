{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting PII using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is generating dataset by using faker lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "      <th>PII</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suite 426 Produce education hand statement. St...</td>\n",
       "      <td>Address</td>\n",
       "      <td>Suite 426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252 Kelly Camp Imagine food analysis so. Reall...</td>\n",
       "      <td>Address</td>\n",
       "      <td>252 Kelly Camp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Education poor interview society on nice simpl...</td>\n",
       "      <td>Address</td>\n",
       "      <td>9202 Jennifer Valleys Suite 890 Port Sara, ID ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Practice enough Apt. 480 learn instead read ro...</td>\n",
       "      <td>Address</td>\n",
       "      <td>Apt. 480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cause example so serious mention. Reflect Amer...</td>\n",
       "      <td>Address</td>\n",
       "      <td>Suite 072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Labels  \\\n",
       "0  Suite 426 Produce education hand statement. St...  Address   \n",
       "1  252 Kelly Camp Imagine food analysis so. Reall...  Address   \n",
       "2  Education poor interview society on nice simpl...  Address   \n",
       "3  Practice enough Apt. 480 learn instead read ro...  Address   \n",
       "4  Cause example so serious mention. Reflect Amer...  Address   \n",
       "\n",
       "                                                 PII  \n",
       "0                                          Suite 426  \n",
       "1                                     252 Kelly Camp  \n",
       "2  9202 Jennifer Valleys Suite 890 Port Sara, ID ...  \n",
       "3                                           Apt. 480  \n",
       "4                                          Suite 072  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_pii = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/train_text_with_pii_2020_10_18_16_36_29_513505.csv')\n",
    "gen_pii.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "      <th>PII</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>Produce education hand statement. Still talk M...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>Imagine food analysis so. Really population en...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Angela Greene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>Education poor interview society on nice simpl...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Amber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>Practice enough learn instead read room. Amy C...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Amy Clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>Cause example so serious mention. Reflect Amer...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Pamela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Today anyone Rhonda message year collection. V...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Rhonda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Smith Some hospital half mean order condition ...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Describe space mission performance. Resource r...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Conference certain we condition only concern. ...</td>\n",
       "      <td>Name</td>\n",
       "      <td>Annette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Nicole Allen Mother himself time three brother.</td>\n",
       "      <td>Name</td>\n",
       "      <td>Nicole Allen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Labels            PII\n",
       "3000  Produce education hand statement. Still talk M...   Name         Marcus\n",
       "3001  Imagine food analysis so. Really population en...   Name  Angela Greene\n",
       "3002  Education poor interview society on nice simpl...   Name          Amber\n",
       "3003  Practice enough learn instead read room. Amy C...   Name       Amy Clay\n",
       "3004  Cause example so serious mention. Reflect Amer...   Name         Pamela\n",
       "...                                                 ...    ...            ...\n",
       "3995  Today anyone Rhonda message year collection. V...   Name         Rhonda\n",
       "3996  Smith Some hospital half mean order condition ...   Name          Smith\n",
       "3997  Describe space mission performance. Resource r...   Name        Sanders\n",
       "3998  Conference certain we condition only concern. ...   Name        Annette\n",
       "3999    Nicole Allen Mother himself time three brother.   Name   Nicole Allen\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Querying only person name\n",
    "gen_pii[gen_pii['Labels'] == 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, you have called Virtual bank, this is N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello, you have called Virtual bank, this is L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello, you have called Virtual bank, this is M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, you have called Virtual bank, this is H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello, you have called Virtual bank, this is L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  Hello, you have called Virtual bank, this is N...\n",
       "1  Hello, you have called Virtual bank, this is L...\n",
       "2  Hello, you have called Virtual bank, this is M...\n",
       "3  Hello, you have called Virtual bank, this is H...\n",
       "4  Hello, you have called Virtual bank, this is L..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real dataset\n",
    "conv = pd.read_csv('D:/DSBA/Project/Final-Project-2/data/Text files/text.csv')\n",
    "conv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try with generating dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More from: https://spacy.io/usage/spacy-101#annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = gen_pii['Text'][3003].lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(r'C:/Users/Namwater/anaconda3/Lib/site-packages/en_core_web_sm/en_core_web_sm-2.3.1')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about annotation: https://spacy.io/api/annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Linguistic annotations\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text:** The original word text.\n",
    "\n",
    "**Lemma:** The base form of the word.\n",
    "\n",
    "**POS:** The simple UPOS part-of-speech tag.\n",
    "\n",
    "**Tag:** The detailed part-of-speech tag.\n",
    "\n",
    "**Dep:** Syntactic dependency, i.e. the relation between tokens.\n",
    "\n",
    "**Shape:** The word shape – capitalization, punctuation, digits.\n",
    "\n",
    "**is alpha:** Is the token an alpha character?\n",
    "\n",
    "**is stop:** Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part of speech\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using spaCy’s built-in displaCy visualizer\n",
    "displacy.render(doc, style = 'dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style = 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ': [', ent.start_char, ',', ent.end_char, '] -', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding IOB Scheme\n",
    "new_tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    print('Text: ' + token.text + ' | Entity: ' + token.ent_type_ + token.ent_iob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    if not token.ent_type_:\n",
    "        new_tokens.append(token.text)\n",
    "    else:\n",
    "        new_tokens.append('xxxx')\n",
    "        \n",
    "new_text = ' '.join(new_tokens)\n",
    "\n",
    "print('new Text->', new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try with conversation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pii_concealer(sent):\n",
    "    \n",
    "    doc = nlp(sent.lower())\n",
    "    new_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.ent_type_:\n",
    "            new_tokens.append(token.text)\n",
    "        else:\n",
    "            new_tokens.append('xxxx')\n",
    "        \n",
    "    new_text = ' '.join(new_tokens)\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Sentence:')\n",
    "print(displacy.render(nlp(conv['Sentence'][0].lower()), style = 'ent'), '\\n')\n",
    "print('After Conceal PII:')\n",
    "print(pii_concealer(conv['Sentence'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the pipeline component\n",
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_data = [\n",
    "              (\"it is 6102651715\", {\"entities\": [(6, 15, \"CARDINAL\")]}),\n",
    "              (\"that is a-p-p-l-e-b-a-u-m.\", {\"entities\": [(8, 24, \"PERSON\")]}),\n",
    "              (\"c-l-a-r-k-s-o-n.\", {\"entities\": [(0, 14, \"PERSON\")]}),\n",
    "              (\"you have called virtual bank\", {\"entities\": [(16, 23, \"ORG\")]}),\n",
    "              (\"this is nancy speaking\", {\"entities\": [(9, 12, 'PERSON')]}),\n",
    "              (\"nicole allen mother himself time three brother.\", {\"entities\": [(0, 11, \"PERSON\")]}),\n",
    "              (\"my name is sandra reed.\", {\"entities\": [(11, 21, \"PERSON\")]}),\n",
    "              (\"that is 874525400.\", {\"entities\": [(8, 16, \"CARDINAL\")]}),\n",
    "              (\"8544702415996.\", {\"entities\": [(0, 13, \"CARDINAL\")]}),\n",
    "              (\"hello debra.\", {\"entities\": [(6, 10, \"PERSON\")]}),\n",
    "              (\"it is in the pattaya beach.\", {\"entities\": [(13, 25, \"GPE\")]})\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels to the `ner`\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(100):\n",
    "\n",
    "    # shuffling examples before every iteration\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(train_data, size = compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop = 0.5,  # dropout - make it harder to memorise data\n",
    "                    losses = losses,\n",
    "                )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "doc = nlp(\"this is nancy speaking.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(displacy.render(nlp(conv['Sentence'][0].lower()), style = 'ent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
