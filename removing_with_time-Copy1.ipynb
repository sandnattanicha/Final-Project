{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated tempo: 78.30 beats per minute\n"
     ]
    }
   ],
   "source": [
    "# Beat tracking example\n",
    "import librosa\n",
    "\n",
    "# 1. Get the file path to an included audio example\n",
    "# filename = librosa.example('\\data\\Voice files\\conversation 18.wav')\n",
    "\n",
    "\n",
    "# 2. Load the audio as a waveform `y`\n",
    "#    Store the sampling rate as `sr`\n",
    "y, sr = librosa.load(\"data/Voice files/conversation 18.wav\")\n",
    "\n",
    "# 3. Run the default beat tracker\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "print('Estimated tempo: {:.2f} beats per minute'.format(tempo))\n",
    "\n",
    "# 4. Convert the frame indices of beat events into timestamps\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.30185941,  0.9752381 ,  1.67183673,  2.43809524,  3.2275737 ,\n",
       "         3.92417234,  4.59755102,  5.29414966,  6.01396825,  6.68734694,\n",
       "         7.33750567,  8.01088435,  8.91646259,  9.79882086, 10.54185941,\n",
       "        11.42421769, 12.28335601, 13.14249433, 13.86231293, 14.60535147,\n",
       "        15.34839002, 16.16108844, 16.97378685, 17.80970522, 18.55274376,\n",
       "        19.31900227, 20.08526077, 20.80507937, 21.501678  , 22.17505669,\n",
       "        22.84843537, 23.63791383, 24.45061224, 25.2400907 , 26.00634921,\n",
       "        26.77260771, 27.53886621, 28.32834467, 29.07138322, 29.79120181,\n",
       "        30.62712018, 31.41659864, 32.25251701, 33.04199546, 33.83147392,\n",
       "        34.73705215, 35.52653061, 36.31600907, 37.15192744, 38.05750567,\n",
       "        38.87020408, 39.68290249, 40.449161  , 41.23863946, 41.95845805,\n",
       "        42.84081633, 43.74639456, 44.65197279, 45.41823129, 46.1844898 ,\n",
       "        46.90430839, 47.69378685, 48.48326531, 49.31918367, 50.08544218,\n",
       "        50.87492063, 51.66439909, 52.56997732, 53.49877551, 54.14893424,\n",
       "        54.84553288, 55.56535147, 56.44770975, 57.21396825, 57.9570068 ,\n",
       "        58.74648526, 59.46630385, 60.32544218, 61.16136054, 61.97405896,\n",
       "        62.83319728]),\n",
       " array([  13,   42,   72,  105,  139,  169,  198,  228,  259,  288,  316,\n",
       "         345,  384,  422,  454,  492,  529,  566,  597,  629,  661,  696,\n",
       "         731,  767,  799,  832,  865,  896,  926,  955,  984, 1018, 1053,\n",
       "        1087, 1120, 1153, 1186, 1220, 1252, 1283, 1319, 1353, 1389, 1423,\n",
       "        1457, 1496, 1530, 1564, 1600, 1639, 1674, 1709, 1742, 1776, 1807,\n",
       "        1845, 1884, 1923, 1956, 1989, 2020, 2054, 2088, 2124, 2157, 2191,\n",
       "        2225, 2264, 2304, 2332, 2362, 2393, 2431, 2464, 2496, 2530, 2561,\n",
       "        2598, 2634, 2669, 2706]),\n",
       " 78.30255681818181)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beat_times, beat_frames, tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      0, 1420256]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.effects.split(y, top_db=80, ref= np.max, frame_length=2048, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/Voice files/conversation 2.wav\"\n",
    "output_path = \"Output/conversation 2.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(input_path, output_path, start= 0, end=30):\n",
    "    input_stream = ffmpeg.input(input_path)\n",
    "\n",
    "    aud = (\n",
    "        input_stream.audio\n",
    "        .filter_('atrim', start=start, end=end)\n",
    "        .filter_('asetpts', 'PTS-STARTPTS')\n",
    "    )\n",
    "\n",
    "    output = ffmpeg.output(aud, output_path)\n",
    "    output.run()\n",
    "\n",
    "trim(\"data/Voice files/conversation 2.wav\", \"Output/conversation 2.wav\", start=0, end=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
